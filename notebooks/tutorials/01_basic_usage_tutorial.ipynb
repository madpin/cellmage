{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd05eb23",
   "metadata": {},
   "source": [
    "# CellMage Magic Functions Tutorial\n",
    "\n",
    "This notebook demonstrates how to use CellMage's powerful magic functions to interact with LLMs directly within your Jupyter notebooks.\n",
    "\n",
    "**Date:** April 24, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7e2ce",
   "metadata": {},
   "source": [
    "## 1. Getting Started with CellMage\n",
    "\n",
    "CellMage provides intuitive IPython magic functions that allow you to interact with Large Language Models without leaving your notebook environment. Let's start by loading the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c35fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:cellmage.config:Found 'llm_conversations' folder. Auto-save enabled automatically.\n",
      "INFO:cellmage.config:Settings loaded successfully using Pydantic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/tpinto/madpin/cellmage/notebooks/tutorials\n",
      "Project root directory: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Added path: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Cellmage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to sys.path so we can import cellmage\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ensure the cellmage package can be imported\n",
    "# Get the absolute path of the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the project root directory (parent of the notebook directory)\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added path: {project_root}\")\n",
    "\n",
    "try:\n",
    "    # Import cellmage\n",
    "    import cellmage\n",
    "\n",
    "    # Check version - handle case where __version__ might not be available\n",
    "    try:\n",
    "        print(f\"Cellmage version: {cellmage.__version__}\")\n",
    "    except AttributeError:\n",
    "        print(\"Cellmage imported successfully, but version information is not available\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error importing cellmage: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    print(\"\\nTry running this notebook from the project root directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ed3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ NotebookLLM Magics loaded. Use %llm_config and %%llm.\n",
      "   For ambient mode, try %llm_config_persistent to process all cells as LLM prompts.\n",
      "CellMage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the CellMage extension\n",
    "%load_ext cellmage\n",
    "\n",
    "# Display version information\n",
    "import cellmage\n",
    "\n",
    "print(f\"CellMage version: {cellmage.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bc60f",
   "metadata": {},
   "source": [
    "## 2. Configuring CellMage with `%llm_config`\n",
    "\n",
    "The `%llm_config` (or equivalently, `%llm_setup`) magic command allows you to configure CellMage's behavior, including setting the default model, selecting personas, and managing conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14aa928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NotebookLLM Status ---\n",
      "Session ID: 50540047-21a5-4a49-ad19-bf63bddeca90\n",
      "None\n",
      "Active Overrides: {'api_key': 'sk-L...mA', 'api_base': 'https://litellm.oracle.madpin.dev', 'model': 'gpt-4.1-nano'}\n",
      "History Length: 0 messages\n",
      "--------------------------\n",
      "✅ Default model set to: gpt-4.1-nano\n",
      "Available Personas: None\n"
     ]
    }
   ],
   "source": [
    "# Basic configuration\n",
    "%llm_config --status\n",
    "\n",
    "# You can set the default LLM model\n",
    "%llm_config --model gpt-4.1-nano\n",
    "\n",
    "# List available personas\n",
    "%llm_config --list-personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492569",
   "metadata": {},
   "source": [
    "### Setting API Credentials\n",
    "\n",
    "To connect to LLM services, you need to provide API credentials. While we recommend using environment variables, you can also set these directly in your notebook:\n",
    "\n",
    "```python\n",
    "%llm_config --api_key \"your-api-key\" --api_base \"https://api.example.com/v1\"\n",
    "```\n",
    "\n",
    "⚠️ **Security Warning**: Never commit notebooks with API keys to version control!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02578cda",
   "metadata": {},
   "source": [
    "## 3. Using the `%%llm` Cell Magic\n",
    "\n",
    "The core functionality of CellMage is the `%%llm` cell magic. Simply add this to the top of any cell, and the cell's content will be sent as a prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f040f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A Jupyter Notebook is an interactive environment that allows you to write and run code directly within your web browser. It’s widely used in data science because it makes exploring data, performing analysis, and creating visualizations very straightforward. Think of it as a digital notebook where you can write code, see the results instantly, and document your findings all in one place, making it easy to experiment, learn, and share your work.\n",
       "\n",
       "In a Jupyter Notebook, you write code in small sections called cells, which can contain Python or other programming languages. After running a cell, you see the output immediately below it, whether it’s numbers, charts, or tables. This step-by-step approach helps you understand your data better and track your progress as you analyze or model it. Additionally, you can include written explanations, images, or links, making your notebooks clear and presentation-ready—perfect for collaboration, learning, or showcasing your projects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ✓ gpt-4.1-nano • 1.26s • 22↓/245↑ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm \n",
    "Explain the concept of a Jupyter notebook to someone new to data science in 2-3 paragraphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de8731",
   "metadata": {},
   "source": [
    "### Using Options with `%%llm`\n",
    "\n",
    "You can customize the behavior of individual LLM interactions by passing options to the `%%llm` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d83f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Silent lines unfurl,  \n",
       "Logic dances through the code—  \n",
       "Python’s flow brings life."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ✓ gpt-4.1 • 1.00s • 279↓/20↑ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm --model gpt-4.1 --temperature 1.5\n",
    "Write a haiku about programmin2g in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5a05c",
   "metadata": {},
   "source": [
    "## 4. Working with Personas\n",
    "\n",
    "Personas are predefined configurations that include system prompts and LLM parameters. They help you quickly switch between different interaction styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e95b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 15:12:57,859 - cellmage.resources.file_loader - WARNING - Persona 'python_expert' not found in llm_personas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: Persona 'python_expert' not found.\n",
      "  To list available personas, use: %llm_config --list-personas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #ffebee; border: 1px solid #ef9a9a; color: #c62828;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ⚠ • 0.01s\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm --persona python_expert\n",
    "Explain how decorators work in Python with a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d97839d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 15:12:57,881 - cellmage.resources.file_loader - WARNING - Persona 'creative_writer' not found in llm_personas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: Persona 'creative_writer' not found.\n",
      "Active Persona: None\n",
      "  To set a persona, use: %llm_config --persona <name>\n",
      "  To list available personas, use: %llm_config --list-personas\n"
     ]
    }
   ],
   "source": [
    "# Set a default persona for all subsequent interactions\n",
    "%llm_config --persona creative_writer\n",
    "%llm_config --show-persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a652756c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In circuits born a spark takes flight,  \n",
       "A mind that learns in day and night.  \n",
       "Patterns woven, deep and wide,  \n",
       "A thinking partner by our side.  \n",
       "\n",
       "Yet wisdom grows with every gain,  \n",
       "As we guide its gentle reign.  \n",
       "A mirror of our endless quest—  \n",
       "To understand, create, and rest."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ✓ gpt-4.1-nano • 0.86s • 313↓/70↑ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm\n",
    "Write a short poem about artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93190aee",
   "metadata": {},
   "source": [
    "## 5. Managing Conversation History\n",
    "\n",
    "CellMage automatically maintains conversation history to provide context for your interactions. You can manage this history using various commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1117bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- History (6 messages) ---\n",
      "[0] USER: Explain the concept of a Jupyter notebook to someone new to data science in 2-3 paragraphs.\n",
      "    (ID: ...64acba, Cell: ZQ%3D%3D, Exec: 4)\n",
      "[1] ASSISTANT: A Jupyter Notebook is an interactive environment that allows you to write and run code directly within your web browser. It’s widely used in data scie...\n",
      "    (ID: ...d83c03, Cell: ZQ%3D%3D, Exec: 4)\n",
      "[2] USER: Write a haiku about programmin2g in Python.\n",
      "    (ID: ...256d89, Cell: ZQ%3D%3D, Exec: 5)\n",
      "[3] ASSISTANT: Silent lines unfurl,  \n",
      "Logic dances through the code—  \n",
      "Python’s flow brings life.\n",
      "    (ID: ...99a432, Cell: ZQ%3D%3D, Exec: 5)\n",
      "[4] USER: Write a short poem about artificial intelligence.\n",
      "    (ID: ...4c777a, Cell: ZQ%3D%3D, Exec: 8)\n",
      "[5] ASSISTANT: In circuits born a spark takes flight,  \n",
      "A mind that learns in day and night.  \n",
      "Patterns woven, deep and wide,  \n",
      "A thinking partner by our side.  \n",
      "\n",
      "Ye...\n",
      "    (ID: ...a7a044, Cell: ZQ%3D%3D, Exec: 8)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show the current conversation history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "987a26be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat history cleared.\n",
      "--- History (0 messages) ---\n",
      "(empty)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Clear the conversation history\n",
    "%llm_config --clear-history\n",
    "\n",
    "# Verify that the history is cleared\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca7367",
   "metadata": {},
   "source": [
    "### Automatic Rollback\n",
    "\n",
    "One of CellMage's most useful features is automatic rollback. When you re-run a cell that contains `%%llm`, CellMage automatically removes the previous interaction from that cell from the history. This prevents duplication when you're iterating on your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4fa6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In the context of CellMage, an \"automatic rollback\" refers to a feature or mechanism that reverts changes or operations to a previous stable state automatically when certain conditions are met, such as errors, failures, or inconsistencies during data processing or model training. This ensures data integrity and consistency by undoing any partial or faulty updates without requiring manual intervention. Essentially, if an error occurs during a workflow or a cell operation, CellMage's automatic rollback restores the system or data to a known good state, minimizing potential disruptions and maintaining reliable operation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ✓ gpt-4.1-nano • 1.20s • 16↓/156↑ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm\n",
    "Explain what 'automatic rollback' means in the context of CellMage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe1df1",
   "metadata": {},
   "source": [
    "## 6. Using Snippets\n",
    "\n",
    "Snippets allow you to include code or other content as context in your LLM conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01b25ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/example_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/example_code.py\n",
    "\n",
    "\n",
    "def process_data(data_list):\n",
    "    \"\"\"Process a list of numeric data.\"\"\"\n",
    "    results = []\n",
    "    for item in data_list:\n",
    "        if isinstance(item, (int, float)):\n",
    "            results.append(item * 2)\n",
    "        else:\n",
    "            print(f\"Skipping non-numeric item: {item}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_data = [1, 2, \"3\", 4.5, \"text\"]\n",
    "processed = process_data(sample_data)\n",
    "print(f\"Processed data: {processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780b652",
   "metadata": {},
   "source": [
    "Now we can list available snippets and add one to our conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70647b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Snippets: None\n"
     ]
    }
   ],
   "source": [
    "# List available snippets\n",
    "%llm_config --list-snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a7919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing arguments: unrecognized arguments: --snippets /tmp/example_code.py system\n"
     ]
    }
   ],
   "source": [
    "# Use our file as a snippet\n",
    "%llm_config --snippets /tmp/example_code.py system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48a11de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 15:12:59,990 - cellmage.resources.file_loader - WARNING - Persona 'python_expert' not found in llm_personas\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error: Persona 'python_expert' not found.\n",
      "  To list available personas, use: %llm_config --list-personas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #ffebee; border: 1px solid #ef9a9a; color: #c62828;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ⚠ • 0.00s\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm --persona python_expert\n",
    "Review the code I provided. How could I improve the error handling and make the function more robust?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c12c7",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Conversations\n",
    "\n",
    "CellMage allows you to save your conversation history and load it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9303f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Unexpected error saving session: 'ChatManager' object has no attribute 'save_session'\n"
     ]
    }
   ],
   "source": [
    "# Save the current conversation\n",
    "%llm_config --save code_review_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "532da41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chat history cleared.\n"
     ]
    }
   ],
   "source": [
    "# Clear history\n",
    "%llm_config --clear-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73f049d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error listing saved sessions: 'ChatManager' object has no attribute 'list_saved_sessions'\n"
     ]
    }
   ],
   "source": [
    "# List available saved sessions\n",
    "%llm_config --list-sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "290836ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Unexpected error loading session 'code_review_session': 'ChatManager' object has no attribute 'load_session'\n",
      "--- History (0 messages) ---\n",
      "(empty)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load a previously saved session\n",
    "%llm_config --load code_review_session\n",
    "\n",
    "# Show the loaded history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40607d",
   "metadata": {},
   "source": [
    "## 8. Using Parameter Overrides\n",
    "\n",
    "You can temporarily override LLM parameters for specific interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f651cd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Override set: temperature = 0.9 (float)\n",
      "Active Overrides: {'api_key': 'sk-L...mA', 'api_base': 'https://litellm.oracle.madpin.dev', 'model': 'gpt-4.1-nano', 'temperature': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Set a parameter override\n",
    "%llm_config --set-override temperature 0.9\n",
    "\n",
    "# Show current overrides\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c22af50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Certainly! Here are three innovative startup ideas merging artificial intelligence with sustainable energy:\n",
       "\n",
       "1. **AI-Driven Renewable Resource Optimization Platform**  \n",
       "A platform that uses machine learning algorithms to analyze weather patterns, sunlight, wind speeds, and energy consumption data in real-time. It dynamically optimizes the operation of renewable energy farms (solar, wind, hydro) by predicting peak generation times and adjusting energy storage and distribution accordingly. This maximizes efficiency, reduces waste, and ensures reliable energy supply.\n",
       "\n",
       "2. **Smart Energy Forecasting and Maintenance System**  \n",
       "An AI-powered service that predicts maintenance needs and potential failures in renewable energy infrastructure before they occur. By analyzing sensor data from turbines, solar panels, and batteries, it schedules proactive maintenance, reduces downtime, and extends equipment lifespan. This not only enhances sustainability by minimizing resource waste but also lowers operational costs for energy providers.\n",
       "\n",
       "3. **Decentralized AI-Enabled Microgrid Management**  \n",
       "A platform that employs artificial intelligence to manage decentralized microgrids in remote or underserved areas. The system intelligently balances local renewable generation, storage, and consumption, optimizing energy flow and reducing dependence on fossil fuels. It can integrate with IoT devices and local production sources, providing resilient and sustainable energy solutions tailored to community needs.\n",
       "\n",
       "Would you like more details on any of these ideas?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ✓ gpt-4.1-nano • 1.57s • 23↓/389↑ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm\n",
    "Generate three creative startup ideas combining artificial intelligence and sustainable energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "205edb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All overrides cleared.\n",
      "Active Overrides: None\n"
     ]
    }
   ],
   "source": [
    "# Clear all overrides\n",
    "%llm_config --clear-overrides\n",
    "\n",
    "# Verify overrides are cleared\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d8eb0",
   "metadata": {},
   "source": [
    "## 9. Ambient Mode with `%llm_setup_forever`\n",
    "\n",
    "For a pure chat experience, you can enable \"Ambient Enchantment\" mode, which treats all regular code cells as prompts for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0801b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%llm_setup_forever` not found.\n"
     ]
    }
   ],
   "source": [
    "# Enable ambient mode\n",
    "%llm_setup_forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regular cell will be treated as a prompt for the LLM\n",
    "What are three best practices for writing clean, maintainable Python code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable ambient mode when you're done\n",
    "%disable_llm_config_persistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e9ceb",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting and Tips\n",
    "\n",
    "Here are some common issues and how to resolve them:\n",
    "\n",
    "1. **Magic commands not found**: Make sure you've loaded the extension with `%load_ext cellmage`\n",
    "2. **API connection errors**: Check your API key and connection settings\n",
    "3. **Missing personas or snippets**: Use `--list-personas` or `--list-snippets` to check available resources\n",
    "4. **Memory errors**: Try clearing history with `--clear-history` to free up memory\n",
    "5. **Import errors**: Verify the CellMage package is correctly installed in your Python path\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Use `--no-stream` for non-interactive tasks to get the full response at once\n",
    "- Keep conversation history concise for faster responses\n",
    "- Choose appropriate models for your task (smaller models for simple tasks, larger models for complex reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ace29",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "CellMage's magic functions provide a seamless way to integrate LLM capabilities directly into your Jupyter workflow. By using these magic commands, you can:\n",
    "\n",
    "- Interact with LLMs without leaving your notebook\n",
    "- Maintain conversation context across cells\n",
    "- Customize LLM behavior with personas and parameter settings\n",
    "- Save and load conversations for later use\n",
    "- Provide additional context through snippets\n",
    "\n",
    "This makes CellMage a powerful tool for data scientists, researchers, and developers who want to leverage LLMs in their workflow.\n",
    "\n",
    "Happy conjuring! ✨🧙‍♂️"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
