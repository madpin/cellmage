{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84f90b3",
   "metadata": {},
   "source": [
    "# ðŸ§™ CellMage Persistent Chat Example âœ¨\n",
    "\n",
    "This notebook demonstrates how to use CellMage's persistent chat capabilities, which allow you to maintain conversation context and persona settings across cells and sessions.\n",
    "\n",
    "**Date:** April 26, 2025\n",
    "\n",
    "## What is Persistent Chat?\n",
    "\n",
    "Persistent chat in CellMage combines two powerful features:\n",
    "1. **Context Retention**: The LLM remembers previous interactions in your conversation\n",
    "2. **Ambient Mode**: Process regular cells as prompts to the LLM without magic commands\n",
    "\n",
    "This creates a seamless chat experience where you can simply type natural language in code cells and get responses while maintaining the full conversation history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf044e",
   "metadata": {},
   "source": [
    "## 1. Setting Up CellMage\n",
    "\n",
    "First, let's load the CellMage extension and ensure it's properly initialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c35fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NotebookLLM Magics loaded. Use %llm_config and %%llm.\n",
      "   For ambient mode, try %llm_config_persistent to process all cells as LLM prompts.\n",
      "âœ… NotebookLLM Magics loaded. Use %llm_config and %%llm.\n",
      "   For ambient mode, try %llm_config_persistent to process all cells as LLM prompts.\n"
     ]
    }
   ],
   "source": [
    "# Load the extension\n",
    "%load_ext cellmage\n",
    "\n",
    "# Import the necessary modules\n",
    "import cellmage\n",
    "print(f\"CellMage version: {cellmage.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848ea43b",
   "metadata": {},
   "source": [
    "## 2. Setting Up Personas and Context\n",
    "\n",
    "One of the most powerful features of CellMage is the ability to define personas - specialized configurations that include system prompts and LLM parameters. These help shape the LLM's responses to better suit your needs.\n",
    "\n",
    "In this example, we'll set up a persistent chat with:\n",
    "- A specific model: `gpt-4.1-mini`\n",
    "- The \"coder\" persona: specialized for coding tasks\n",
    "- System snippets: additional context about \"Thiago\" and \"EVO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aa928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Default model set to: gpt-4.1-mini\n",
      "âœ… Added system snippet: 'Thiago'\n",
      "âœ… Added system snippet: 'EVO'\n",
      "âœ… Persona activated: 'coder'\n",
      "âœ… Ambient mode ENABLED. All cells will now be processed as LLM prompts unless they start with % or !.\n",
      "   Run %disable_llm_config_persistent to disable ambient mode.\n"
     ]
    }
   ],
   "source": [
    "# Configure the CellMage environment for persistent chat\n",
    "%llm_config_persistent --model gpt-4.1-mini --persona coder --sys-snippet Thiago --sys-snippet EVO\n",
    "\n",
    "# Note: %llm_config_persistent combines:\n",
    "# 1. %llm_config (normal configuration)\n",
    "# 2. %llm_setup_forever (enabling ambient mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a748e7",
   "metadata": {},
   "source": [
    "### What Are System Snippets?\n",
    "\n",
    "System snippets provide additional context to the LLM as part of the system message. They can include:\n",
    "- Information about users or entities (like \"Thiago\" in our example)\n",
    "- Domain knowledge (like \"EVO\" - a project or concept)\n",
    "- Instructions for how the LLM should respond\n",
    "- Code examples or other technical context\n",
    "\n",
    "In this example, we've included two snippet files that should be located in your `snippets/` directory:\n",
    "- `Thiago.md`: Contains information about a person named Thiago\n",
    "- `EVO.md`: Contains information about a concept or project called EVO\n",
    "\n",
    "Let's examine the active persona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5590393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the active persona configuration\n",
    "%llm_config --show-persona"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ead7c0",
   "metadata": {},
   "source": [
    "## 3. Starting a Persistent Chat\n",
    "\n",
    "Now that ambient mode is enabled with our persona and snippets, we can start chatting. Simply type natural language in code cells and run them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f6555f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            âœ“ gpt-4.1-mini â€¢ 0.68s â€¢ 917â†“/8â†‘ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hello there!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d651f0",
   "metadata": {},
   "source": [
    "### Viewing Conversation History\n",
    "\n",
    "CellMage maintains a history of your conversation. You can view this history at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f040f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- History (5 messages) ---\n",
      "[0] SYSTEM: You are Coder, an elite technical assistant specializing in software engineering and system architecture. Your primary focus is delivering optimal sol...\n",
      "    (ID: ...216958, Cell: ZQ%3D%3D, Exec: 2)\n",
      "[1] SYSTEM: Thiago Madeira Pinto is a 38-year-old Brazilian software engineer and team manager, currently living in Dublin, Ireland. He was born on October 8, 198...\n",
      "    (ID: ...379b5f, Cell: ZQ%3D%3D, Exec: 2)\n",
      "[2] SYSTEM: EVO, which stands for Employer Value Optimization, is a team within Indeed that focuses on maximizing return on investment (ROI) for the Sales, Client...\n",
      "    (ID: ...be728a, Cell: ZQ%3D%3D, Exec: 2)\n",
      "[3] USER: Hello there!\n",
      "    (ID: ...abdeba, Cell: ZQ%3D%3D, Exec: 3)\n",
      "[4] ASSISTANT: Hello! How can I assist you today?\n",
      "    (ID: ...8d8d95, Cell: ZQ%3D%3D, Exec: 3)\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the current conversation history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af0471",
   "metadata": {},
   "source": [
    "## 4. Contextual Awareness\n",
    "\n",
    "One of the key features of persistent chat is that the LLM maintains context from previous interactions. Let's test this by providing some information and then asking the LLM to recall it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d106032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi Thiago! How can I help you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            âœ“ gpt-4.1-mini â€¢ 0.70s â€¢ 930â†“/9â†‘ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "My name is Thiago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc10dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "What's my name?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc7adb",
   "metadata": {},
   "source": [
    "Notice how the LLM remembers the name from the previous interaction. This contextual awareness comes from two sources:\n",
    "\n",
    "1. **System Context**: Information provided in the system snippets (Thiago.md)\n",
    "2. **Conversation History**: Previous turns in the conversation\n",
    "\n",
    "Let's check the full history again to see how it's maintaining context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6195d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcd466",
   "metadata": {},
   "source": [
    "## 5. Creative Tasks in Persistent Chats\n",
    "\n",
    "Persistent chats are particularly useful for creative tasks like storytelling, where the LLM can build upon previous context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ac772",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tell me a short story about a software engineer named Thiago who works on an AI project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84167179",
   "metadata": {},
   "source": [
    "## 6. Advanced: Saving and Loading Conversations\n",
    "\n",
    "CellMage allows you to save your conversations for later use. This is particularly useful for long-running projects where you want to pick up where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a12550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current conversation\n",
    "%llm_config --save thiago_conversation\n",
    "\n",
    "print(\"Conversation saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the current conversation history\n",
    "%llm_config --clear-history\n",
    "\n",
    "# Verify that history is cleared\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved conversation\n",
    "%llm_config --load thiago_conversation\n",
    "\n",
    "# Verify that the conversation is loaded\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aac4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Can you continue the story about Thiago, but have him solve a challenging technical problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f353cdd8",
   "metadata": {},
   "source": [
    "## 8. Best Practices for Persistent Chats\n",
    "\n",
    "To get the most out of persistent chats in CellMage, follow these best practices:\n",
    "\n",
    "1. **Use descriptive personas**: Create specialized personas for different tasks (coding, writing, brainstorming)\n",
    "2. **Provide rich context**: Use system snippets to give the LLM the information it needs\n",
    "3. **Save important conversations**: Use the `--save` option to preserve valuable interactions\n",
    "4. **Monitor conversation length**: Very long conversations can hit context limits and increase cost\n",
    "5. **Reset when switching topics**: Use `--clear-history` when starting a new topic\n",
    "6. **Use `--show-history`**: Regularly check what context the LLM is working with\n",
    "\n",
    "## 9. Disabling Persistent Chat\n",
    "\n",
    "When you're done with your persistent chat session, you should disable ambient mode to return to normal notebook operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2401ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable ambient mode\n",
    "%disable_llm_config_persistent\n",
    "\n",
    "print(\"Persistent chat mode disabled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e0f72",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Persistent chat in CellMage provides a powerful way to maintain conversational context while interacting with LLMs in your notebooks. Combined with personas and system snippets, it creates a rich, interactive experience tailored to your specific needs.\n",
    "\n",
    "This approach is particularly valuable for:\n",
    "- Extended brainstorming sessions\n",
    "- Creating and refining code with an AI assistant\n",
    "- Educational scenarios where context builds over time\n",
    "- Creative writing and storytelling\n",
    "\n",
    "For more examples and tutorials, check out the [tutorials directory](../tutorials/) or return to the [main README](../README.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11756519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thiago, hereâ€™s a short story inspired by you:\n",
       "\n",
       "In the vibrant city of Dublin, a skilled software engineer named Thiago balanced code and leadership with a passion for learning. Every morning, after a brisk walk through cobblestone streets, heâ€™d dive into complex data problems at Indeedâ€™s EVO team, crafting machine learning models that gave sales reps the perfect leads at just the right moment. Outside work, heâ€™d unwind watching \"Matrix\" or sharing Brazilian snacks with Rachel, dreaming of his next European adventure. Though a bit shy, Thiagoâ€™s quiet strength and curiosity always led him to new discoveriesâ€”both in technology and life."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            âœ“ gpt-4.1-mini â€¢ 1.89s â€¢ 956â†“/160â†‘ tokens\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tell me a short story about a software engineer named Thiago who works on an AI project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
