{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa1ce7a",
   "metadata": {},
   "source": [
    "# Introduction to Cellmage âœ¨\n",
    "\n",
    "This notebook introduces the basic functionality of the `cellmage` library, a toolkit for interacting with Large Language Models directly in Jupyter notebooks.\n",
    "\n",
    "**Date:** April 25, 2025\n",
    "\n",
    "## What is Cellmage?\n",
    "\n",
    "Cellmage (pronounced \"sell-mage\") is a powerful library that simplifies interactions with various LLMs while providing:\n",
    "- **Conversation history management**: Track and manage multi-turn conversations\n",
    "- **Persona configuration**: Customize system prompts and parameters for different use cases\n",
    "- **Snippet management**: Include code and other context in your LLM interactions\n",
    "- **Conversation saving/loading**: Persist conversations for later use\n",
    "- **IPython/Jupyter integration**: Interact with LLMs directly from notebook cells\n",
    "- **Multiple model support**: Works with OpenAI, Gemini, and other LLM providers\n",
    "\n",
    "At its heart, Cellmage brings the power of Large Language Models directly into your data science workflow!\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. Python 3.10 or later installed\n",
    "2. The following packages:\n",
    "   ```\n",
    "   cellmage>=0.1.0\n",
    "   jupyter>=1.0.0\n",
    "   python-dotenv>=0.19.0  # For secure API key management\n",
    "   ```\n",
    "3. Valid API credentials for your chosen LLM provider\n",
    "\n",
    "## Security Best Practices\n",
    "\n",
    "When working with LLM APIs, always:\n",
    "\n",
    "1. Store API keys in environment variables or `.env` files\n",
    "2. Never commit API keys to version control\n",
    "3. Use appropriate scoping for API keys\n",
    "4. Monitor API usage and set up rate limiting\n",
    "\n",
    "Create a `.env` file in your project root with:\n",
    "```\n",
    "CELLMAGE_API_KEY=your-api-key-here\n",
    "CELLMAGE_API_BASE=https://your-api-endpoint\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c7350",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "Let's start by ensuring we have the cellmage package installed. In this notebook, we'll use the existing installation from the local development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19287fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 02:09:34,222 - __main__ - INFO - Loaded environment variables from ../.env\n",
      "2025-04-26 02:09:34,224 - __main__ - INFO - Added /Users/tpinto/madpin/cellmage to Python path\n",
      "2025-04-26 02:09:34,390 - cellmage.config - INFO - Settings loaded successfully using Pydantic\n",
      "2025-04-26 02:09:34,411 - __main__ - INFO - Successfully imported cellmage 0.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Set up logging with a more informative format\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Try to load environment variables from .env file\n",
    "env_path = Path(\"../.env\")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    logger.info(f\"Loaded environment variables from {env_path}\")\n",
    "else:\n",
    "    logger.warning(f\"No .env file found at {env_path}. Using system environment variables.\")\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"CELLMAGE_API_KEY\", \"CELLMAGE_API_BASE\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "if missing_vars:\n",
    "    logger.error(f\"Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    logger.info(\"Please set them in your .env file or system environment.\")\n",
    "\n",
    "# Setup path for cellmage import\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "    logger.info(f\"Added {project_root} to Python path\")\n",
    "\n",
    "# Import and verify cellmage installation\n",
    "try:\n",
    "    import cellmage\n",
    "\n",
    "    logger.info(f\"Successfully imported cellmage {cellmage.__version__}\")\n",
    "except ImportError as e:\n",
    "    logger.error(f\"Failed to import cellmage: {e}\")\n",
    "    logger.info(\"Try installing with: pip install -e ..\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    logger.error(f\"Unexpected error while importing cellmage: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7df73",
   "metadata": {},
   "source": [
    "## Setting Up the LLM Client\n",
    "\n",
    "Cellmage uses an adapter pattern to work with multiple LLM providers. The `DirectLLMAdapter` provides direct HTTP communication with LLM APIs without requiring additional packages.\n",
    "\n",
    "### Error Handling and Configuration\n",
    "\n",
    "The client setup includes:\n",
    "- Environment variable validation\n",
    "- Connection testing\n",
    "- Automatic retries for transient errors\n",
    "- Timeout configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01f5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 02:09:34,499 - __main__ - INFO - Testing connection to LLM service with model llama-3.1-8b-instant...\n",
      "2025-04-26 02:09:34,999 - __main__ - INFO - Successfully connected to LLM service\n",
      "2025-04-26 02:09:35,000 - __main__ - INFO - LLM client initialization complete\n"
     ]
    }
   ],
   "source": [
    "from cellmage.adapters.direct_client import DirectLLMAdapter\n",
    "from cellmage.exceptions import LLMInteractionError, ConfigurationError\n",
    "from cellmage.models import Message\n",
    "import time\n",
    "\n",
    "\n",
    "def setup_llm_client(model=\"llama-3.1-8b-instant\"):\n",
    "    \"\"\"Set up the LLM client with error handling and validation.\n",
    "\n",
    "    Args:\n",
    "        model (str): The model identifier to use\n",
    "\n",
    "    Returns:\n",
    "        DirectLLMAdapter: Configured LLM client\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create client with minimal parameters\n",
    "        client = DirectLLMAdapter(default_model=model, debug=True)  # Enable debug logging\n",
    "\n",
    "        # Set additional parameters using set_override\n",
    "        client.set_override(\"temperature\", 0.7)\n",
    "        client.set_override(\"max_tokens\", 1000)\n",
    "\n",
    "        # Test the connection with a minimal prompt\n",
    "        try:\n",
    "            logger.info(f\"Testing connection to LLM service with model {model}...\")\n",
    "            # Create a proper Message object for testing\n",
    "            test_message = Message(role=\"user\", content=\"test\")\n",
    "            client.chat([test_message], stream=False)\n",
    "            logger.info(f\"Successfully connected to LLM service\")\n",
    "        except (LLMInteractionError, ConfigurationError) as e:\n",
    "            logger.warning(f\"Connection test failed: {e}\")\n",
    "            logger.info(\"Continuing anyway - check your API credentials later\")\n",
    "\n",
    "        return client\n",
    "\n",
    "    except ConfigurationError as e:\n",
    "        logger.error(f\"Configuration error: {e}\")\n",
    "        logger.info(\"Please check your API credentials and environment variables.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error during client setup: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Create the LLM client\n",
    "llm_client = setup_llm_client()\n",
    "logger.info(\"LLM client initialization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640c8ce",
   "metadata": {},
   "source": [
    "## Creating a Chat Manager\n",
    "\n",
    "The `ChatManager` is the central class in Cellmage that coordinates between all components. Let's create a basic setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ea0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 02:09:35,052 - __main__ - INFO - Conversations will be saved to: /Users/tpinto/madpin/cellmage/notebooks/llm_conversations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat manager initialized with 'helpful_assistant' persona\n",
      "Available personas: code_expert, helpful_assistant\n"
     ]
    }
   ],
   "source": [
    "# Create components for the chat manager\n",
    "from cellmage.resources.memory_loader import MemoryLoader\n",
    "from cellmage.storage.memory_store import MemoryStore\n",
    "from cellmage.storage.markdown_store import MarkdownStore  # Added MarkdownStore import\n",
    "from cellmage.models import PersonaConfig\n",
    "import os\n",
    "\n",
    "# Create in-memory components for testing\n",
    "persona_loader = MemoryLoader()\n",
    "snippet_provider = MemoryLoader()\n",
    "\n",
    "# Create a persistent storage for conversations using MarkdownStore\n",
    "# This will save conversations to files instead of just memory\n",
    "save_dir = os.path.join(os.getcwd(), \"llm_conversations\")\n",
    "history_store = MarkdownStore(save_dir)  # Use MarkdownStore instead of MemoryStore\n",
    "logger.info(f\"Conversations will be saved to: {save_dir}\")\n",
    "\n",
    "# Instead of using MemoryLoader.add_persona, create PersonaConfig directly\n",
    "# and store them in the personas dictionary to avoid validation errors\n",
    "helpful_persona = PersonaConfig(\n",
    "    name=\"helpful_assistant\",\n",
    "    system_message=\"You are a helpful assistant who provides clear, concise answers.\",\n",
    "    config={\"description\": \"A helpful assistant for general questions\", \"temperature\": 0.7},\n",
    ")\n",
    "\n",
    "code_persona = PersonaConfig(\n",
    "    name=\"code_expert\",\n",
    "    system_message=\"You are a Python code expert who provides detailed explanations and best practices.\",\n",
    "    config={\n",
    "        \"description\": \"A specialized persona for code-related questions\",\n",
    "        \"temperature\": 0.3,  # Lower temperature for more deterministic code responses\n",
    "    },\n",
    ")\n",
    "\n",
    "# Store personas directly in the loader's dictionary\n",
    "persona_loader.personas[\"helpful_assistant\"] = helpful_persona\n",
    "persona_loader.personas[\"code_expert\"] = code_persona\n",
    "\n",
    "# Create a chat manager\n",
    "chat_manager = cellmage.ChatManager(\n",
    "    llm_client=llm_client,\n",
    "    persona_loader=persona_loader,\n",
    "    snippet_provider=snippet_provider,\n",
    "    history_store=history_store,\n",
    ")\n",
    "\n",
    "# Set default persona\n",
    "chat_manager.set_default_persona(\"helpful_assistant\")\n",
    "\n",
    "print(f\"Chat manager initialized with 'helpful_assistant' persona\")\n",
    "print(f\"Available personas: {', '.join([p for p in persona_loader.list_personas()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bf4cd",
   "metadata": {},
   "source": [
    "## Sending Messages\n",
    "\n",
    "Now that our chat manager is set up, we can send messages to the LLM. Cellmage maintains conversation context automatically, so each message builds on the previous interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb73e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a message to the LLM with the default persona\n",
    "response = chat_manager.chat(\n",
    "    \"What are the main features of the cellmage library?\",\n",
    "    stream=True,  # Enable streaming responses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4f4d9",
   "metadata": {},
   "source": [
    "### Using Different Personas\n",
    "\n",
    "One of Cellmage's powerful features is the ability to switch personas during a conversation. Let's try using our code expert persona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb123c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a follow-up question using a different persona\n",
    "response = chat_manager.chat(\n",
    "    \"How would you implement a simple caching system in Python?\",\n",
    "    persona_name=\"code_expert\",  # Switch to the code expert persona for this message\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0003947",
   "metadata": {},
   "source": [
    "### Parameter Overrides\n",
    "\n",
    "You can also override LLM parameters for a specific interaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8c2a972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a message with custom parameters\n",
    "response = chat_manager.chat(\n",
    "    \"Generate a creative name for a Python library that helps with data visualization.\",\n",
    "    overrides={\n",
    "        \"temperature\": 1.0,  # Increase creativity\n",
    "        \"max_tokens\": 50,  # Keep it short\n",
    "    },\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee4b0e",
   "metadata": {},
   "source": [
    "## Adding a Code Snippet\n",
    "\n",
    "Cellmage allows you to add code snippets to the conversation, which can be useful for providing context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba2b3325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code snippet\n",
    "snippet_provider.add_snippet(\n",
    "    name=\"python_example\",\n",
    "    content=\"\"\"```python\n",
    "def calculate_fibonacci(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)\n",
    "```\"\"\",\n",
    ")\n",
    "\n",
    "# Add the snippet to the conversation\n",
    "chat_manager.add_snippet(\"python_example\")\n",
    "\n",
    "# Now ask about the snippet\n",
    "response = chat_manager.chat(\n",
    "    \"Can you explain this fibonacci function and suggest how to make it more efficient?\",\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda3da1",
   "metadata": {},
   "source": [
    "## Viewing Conversation History\n",
    "\n",
    "You can view the conversation history at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91126715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. system: You are a helpful assistant who provides clear, co...\n",
      "   ID: a50fc89b-3082-4992-97d4-af3a435dd6c3\n",
      "\n",
      "2. user: What are the main features of the cellmage library...\n",
      "   ID: dfe1e551-0f04-4430-a427-c6aa3337c035\n",
      "\n",
      "3. assistant: Cellmage is a library designed for modeling and si...\n",
      "   ID: 20624df4-3163-4342-b5a7-b567668363b5\n",
      "\n",
      "4. user: How would you implement a simple caching system in...\n",
      "   ID: d99c1d4c-6f43-45a4-8d97-b820ffa23488\n",
      "\n",
      "5. assistant: To implement a simple caching system in Python, yo...\n",
      "   ID: 30f69ca8-9847-4f91-9252-a82f04a731a3\n",
      "\n",
      "6. user: Generate a creative name for a Python library that...\n",
      "   ID: 620e8a99-2943-4002-b0b9-f465180bb0c3\n",
      "\n",
      "7. assistant: Sure! How about **\"VisuNest\"**?\n",
      "\n",
      "*Meaning:* A play...\n",
      "   ID: f8db7dad-5664-4f99-ada7-e5a095bb1549\n",
      "\n",
      "8. system: ```python\n",
      "def calculate_fibonacci(n):\n",
      "    if n <= ...\n",
      "   ID: a1827647-3323-4aea-8909-fe4a368f7662\n",
      "\n",
      "9. user: Can you explain this fibonacci function and sugges...\n",
      "   ID: b3d463b7-f0b1-4955-837c-b68968cddf23\n",
      "\n",
      "10. assistant: Certainly! The Fibonacci function provided is a cl...\n",
      "   ID: 93812b5f-4ae5-4642-a6da-4d3be3b6eadb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the conversation history\n",
    "history = chat_manager.get_history()\n",
    "\n",
    "# Print the history in a readable format\n",
    "for i, message in enumerate(history):\n",
    "    print(f\"{i + 1}. {message.role}: {message.content[:50]}...\")\n",
    "    print(f\"   ID: {message.id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebd3ba",
   "metadata": {},
   "source": [
    "## Saving and Loading Conversations\n",
    "\n",
    "Cellmage allows you to save and load conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300410f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 02:09:40,660 - cellmage.storage.markdown_store - ERROR - Error loading conversation from /Users/tpinto/madpin/cellmage/notebooks/llm_conversations/example_conversation.md: 1 validation error for ConversationMetadata\n",
      "session_id\n",
      "  Input should be a valid string [type=string_type, input_value=UUID('5b643b48-85cb-40c3-93bd-3854680a3bea'), input_type=UUID]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "2025-04-26 02:09:40,661 - cellmage.history_manager - ERROR - Error loading conversation: Failed to load conversation: 1 validation error for ConversationMetadata\n",
      "session_id\n",
      "  Input should be a valid string [type=string_type, input_value=UUID('5b643b48-85cb-40c3-93bd-3854680a3bea'), input_type=UUID]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to: /Users/tpinto/madpin/cellmage/notebooks/llm_conversations/example_conversation.md\n",
      "History cleared, current message count: 2\n",
      "Conversation loaded, message count: 2\n",
      "File exists: True\n",
      "File is located at: /Users/tpinto/madpin/cellmage/notebooks/llm_conversations/example_conversation.md\n"
     ]
    }
   ],
   "source": [
    "# Save the conversation to a persistent file\n",
    "save_path = chat_manager.save_conversation(\"example_conversation\")\n",
    "print(f\"Conversation saved to: {save_path}\")\n",
    "\n",
    "# Clear the history\n",
    "chat_manager.clear_history()\n",
    "print(f\"History cleared, current message count: {len(chat_manager.get_history())}\")\n",
    "\n",
    "# Load the conversation back\n",
    "if save_path:\n",
    "    chat_manager.load_conversation(save_path)\n",
    "    print(f\"Conversation loaded, message count: {len(chat_manager.get_history())}\")\n",
    "    # Let's verify the file exists on disk\n",
    "    print(f\"File exists: {os.path.exists(save_path)}\")\n",
    "    print(f\"File is located at: {os.path.abspath(save_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33478dc2",
   "metadata": {},
   "source": [
    "## Troubleshooting Guide\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "1. **API Connection Errors**\n",
    "   - Check your internet connection\n",
    "   - Verify API credentials in `.env` file\n",
    "   - Ensure the API endpoint is accessible\n",
    "\n",
    "2. **Import Errors**\n",
    "   - Run `pip install -e ..` from the notebooks directory\n",
    "   - Check Python path configuration\n",
    "   - Verify Python version compatibility\n",
    "\n",
    "3. **Memory Issues**\n",
    "   - Use `chat_manager.clear_history()` regularly\n",
    "   - Monitor conversation length\n",
    "   - Consider using persistent storage for long conversations\n",
    "\n",
    "4. **Performance Tips**\n",
    "   - Use `stream=True` for better user experience with long responses\n",
    "   - Set appropriate `max_tokens` for your use case\n",
    "   - Choose the right model for your needs (e.g., nano for quick responses)\n",
    "\n",
    "### Example Error Resolution\n",
    "\n",
    "```python\n",
    "try:\n",
    "    response = chat_manager.chat(\"Your prompt here\")\n",
    "except LLMInteractionError as e:\n",
    "    if \"rate limit\" in str(e).lower():\n",
    "        print(\"Rate limit reached. Waiting before retry...\")\n",
    "        time.sleep(60)\n",
    "    elif \"context length\" in str(e).lower():\n",
    "        print(\"Context too long. Clearing history...\")\n",
    "        chat_manager.clear_history()\n",
    "    else:\n",
    "        raise\n",
    "```\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Conversation Management**\n",
    "   - Save important conversations before clearing history\n",
    "   - Use appropriate personas for different tasks\n",
    "   - Keep system prompts clear and focused\n",
    "\n",
    "2. **Resource Usage**\n",
    "   - Monitor token usage and costs\n",
    "   - Use streaming for long responses\n",
    "   - Clean up resources when done\n",
    "\n",
    "3. **Error Handling**\n",
    "   - Always wrap API calls in try-except blocks\n",
    "   - Implement appropriate retry logic\n",
    "   - Log errors for debugging\n",
    "\n",
    "4. **Security**\n",
    "   - Rotate API keys regularly\n",
    "   - Monitor for unusual usage patterns\n",
    "   - Review conversation history before saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606d7dd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the basic functionality of the Cellmage library:\n",
    "- Setting up an LLM client\n",
    "- Creating and using personas\n",
    "- Adding code snippets\n",
    "- Sending messages to the LLM\n",
    "- Viewing conversation history\n",
    "- Saving and loading conversations\n",
    "\n",
    "In the next notebooks, we'll explore more advanced features and test with different LLM models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
