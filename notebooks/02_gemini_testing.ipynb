{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ad4a88",
   "metadata": {},
   "source": [
    "# Testing Cellmage with Gemini 2.5 Flash\n",
    "\n",
    "This notebook tests the capabilities of Cellmage with Google's Gemini 2.5 Flash model.\n",
    "\n",
    "**Date:** April 24, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed0e552",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's set up our development environment and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe45b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:04,631 - cellmage - INFO - Cellmage logging initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Project root directory: /Users/tpinto/madpin/cellmage\n",
      "Added path: /Users/tpinto/madpin/cellmage\n",
      "Cellmage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Setup environment\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Skip dotenv loading for testing\n",
    "os.environ[\"CELLMAGE_SKIP_DOTENV\"] = \"1\"\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ensure the cellmage package can be imported\n",
    "# Get the absolute path of the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the project root directory (parent of the notebook directory)\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added path: {project_root}\")\n",
    "\n",
    "try:\n",
    "    # Import cellmage\n",
    "    import cellmage\n",
    "\n",
    "    # Check version - handle case where __version__ might not be available\n",
    "    try:\n",
    "        print(f\"Cellmage version: {cellmage.__version__}\")\n",
    "    except AttributeError:\n",
    "        print(\"Cellmage imported successfully, but version information is not available\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error importing cellmage: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    print(\"\\nTry running this notebook from the project root directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c837ef9",
   "metadata": {},
   "source": [
    "## Setting Up the Gemini LLM Client\n",
    "\n",
    "Now we'll configure the LLM client to use Google's Gemini 2.5 Flash model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf7302d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:04,698 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_key' = sk-L...xxmA\n",
      "2025-04-24 06:22:04,699 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 06:22:04,699 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gemini-2.5-flash\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM client initialized with model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "from cellmage.adapters.direct_client import DirectLLMAdapter\n",
    "\n",
    "# Create an LLM client with Gemini-2.5-flash model\n",
    "# Note: You need to set GOOGLE_API_KEY in your environment\n",
    "llm_client = DirectLLMAdapter(default_model=\"gemini-2.5-flash\")\n",
    "\n",
    "print(\"LLM client initialized with model: gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cddea",
   "metadata": {},
   "source": [
    "## Creating Specialized Personas for Gemini\n",
    "\n",
    "Let's create some specialized personas that work well with Gemini models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8682a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:04,738 - cellmage.resources.memory_loader - INFO - Added persona 'code_expert' to memory\n",
      "2025-04-24 06:22:04,738 - cellmage.resources.memory_loader - INFO - Added persona 'creative_writer' to memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available personas: ['code_expert', 'creative_writer']\n"
     ]
    }
   ],
   "source": [
    "from cellmage.resources.memory_loader import MemoryLoader\n",
    "from cellmage.storage.memory_store import MemoryStore\n",
    "\n",
    "# Create in-memory components for testing\n",
    "persona_loader = MemoryLoader()\n",
    "snippet_provider = MemoryLoader()\n",
    "history_store = MemoryStore()\n",
    "\n",
    "# Create specialized personas\n",
    "persona_loader.add_persona(\n",
    "    name=\"code_expert\",\n",
    "    system_message=\"You are a programming expert who specializes in writing clean, efficient code. Provide detailed explanations and always suggest best practices.\",\n",
    "    config={\"temperature\": 0.3, \"top_p\": 0.95},\n",
    ")\n",
    "\n",
    "persona_loader.add_persona(\n",
    "    name=\"creative_writer\",\n",
    "    system_message=\"You are a creative writing assistant who helps draft engaging stories and content. Be imaginative and suggest unique perspectives.\",\n",
    "    config={\"temperature\": 0.9, \"top_p\": 0.98},\n",
    ")\n",
    "\n",
    "# List available personas\n",
    "print(f\"Available personas: {persona_loader.list_personas()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e99c50",
   "metadata": {},
   "source": [
    "## Creating a Chat Manager with Gemini\n",
    "\n",
    "Now let's set up a Chat Manager with the Gemini model and our personas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e490f4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:04,743 - cellmage.chat_manager - INFO - Initializing ChatManager\n",
      "2025-04-24 06:22:04,743 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 06:22:04,744 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:22:04,744 - cellmage.adapters.direct_client - INFO - [Override] Setting 'top_p' = 0.95\n",
      "2025-04-24 06:22:04,745 - cellmage.chat_manager - INFO - Default persona set to 'code_expert'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat manager initialized with 'code_expert' persona\n"
     ]
    }
   ],
   "source": [
    "# Create a chat manager\n",
    "chat_manager = cellmage.ChatManager(\n",
    "    llm_client=llm_client,\n",
    "    persona_loader=persona_loader,\n",
    "    snippet_provider=snippet_provider,\n",
    "    history_store=history_store,\n",
    ")\n",
    "\n",
    "# Set default persona to code_expert\n",
    "chat_manager.set_default_persona(\"code_expert\")\n",
    "\n",
    "print(\"Chat manager initialized with 'code_expert' persona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e5790",
   "metadata": {},
   "source": [
    "## Testing Code Generation with Gemini\n",
    "\n",
    "Let's test Gemini's code generation capabilities through our chat manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be8f2823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:04,750 - cellmage.chat_manager - INFO - Sending message to LLM with 2 messages in context\n",
      "2025-04-24 06:22:04,751 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 2 messages\n"
     ]
    }
   ],
   "source": [
    "# Add a challenging code generation task\n",
    "response = chat_manager.chat(\n",
    "    \"\"\"Write a Python function that acts as a simple text-based calculator. \n",
    "    It should take a string expression like '2 + 3 * 4' and return the calculated result.\n",
    "    Handle addition, subtraction, multiplication, division, and parentheses.\n",
    "    Make sure to respect the order of operations.\"\"\",\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00650056",
   "metadata": {},
   "source": [
    "## Testing Creative Content Generation\n",
    "\n",
    "Now let's switch to our creative writer persona and test content generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a02a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:22:40,917 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.9\n",
      "2025-04-24 06:22:40,918 - cellmage.adapters.direct_client - INFO - [Override] Setting 'top_p' = 0.98\n",
      "2025-04-24 06:22:40,919 - cellmage.chat_manager - INFO - Default persona set to 'creative_writer'\n",
      "2025-04-24 06:22:40,920 - cellmage.chat_manager - INFO - Sending message to LLM with 4 messages in context\n",
      "2025-04-24 06:22:40,920 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 4 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to 'creative_writer' persona\n"
     ]
    }
   ],
   "source": [
    "# Switch to creative_writer persona\n",
    "chat_manager.set_default_persona(\"creative_writer\")\n",
    "print(\"Switched to 'creative_writer' persona\")\n",
    "\n",
    "# Generate creative content\n",
    "response = chat_manager.chat(\n",
    "    \"\"\"Write a short story about a programmer who discovers an AI that can \n",
    "    predict the future, but only for trivial events. Make it humorous and \n",
    "    include a surprising twist at the end.\"\"\",\n",
    "    stream=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5045d22",
   "metadata": {},
   "source": [
    "## Adding Context with Code Snippets\n",
    "\n",
    "Let's test how Gemini performs with code snippets as context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bad0c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:23:19,265 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:23:19,265 - cellmage.adapters.direct_client - INFO - [Override] Setting 'top_p' = 0.95\n",
      "2025-04-24 06:23:19,266 - cellmage.chat_manager - INFO - Default persona set to 'code_expert'\n",
      "2025-04-24 06:23:19,266 - cellmage.resources.memory_loader - INFO - Added snippet 'buggy_sort' to memory\n",
      "2025-04-24 06:23:19,267 - cellmage.chat_manager - INFO - Added snippet 'buggy_sort' as system message\n",
      "2025-04-24 06:23:19,267 - cellmage.chat_manager - INFO - Sending message to LLM with 7 messages in context\n",
      "2025-04-24 06:23:19,267 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 7 messages\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch back to code_expert persona\n",
    "chat_manager.set_default_persona(\"code_expert\")\n",
    "\n",
    "# Create a code snippet with a bug\n",
    "snippet_provider.add_snippet(\n",
    "    name=\"buggy_sort\",\n",
    "    content=\"\"\"```python\n",
    "def bubble_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j], arr[j+1]  # Bug: This line is correct but there's a logical error\n",
    "    return arr\n",
    "\n",
    "# Test the function\n",
    "test_array = [64, 34, 25, 12, 22, 11, 90]\n",
    "sorted_array = bubble_sort(test_array)\n",
    "print(\"Sorted array:\", sorted_array)\n",
    "```\"\"\",\n",
    ")\n",
    "\n",
    "# Add the snippet to the conversation\n",
    "chat_manager.add_snippet(\"buggy_sort\")\n",
    "\n",
    "# Ask about the bug\n",
    "response = chat_manager.chat(\n",
    "    \"\"\"There's a logical error in this bubble sort implementation. \n",
    "    The function seems to work correctly for this test case, but it's not implemented optimally. \n",
    "    Can you identify the issue and suggest a fix?\"\"\",\n",
    "    stream=True,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570075a",
   "metadata": {},
   "source": [
    "## Comparing Gemini's Performance\n",
    "\n",
    "Let's create a complex query and test it with temperature variations to see how Gemini's responses differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032275b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:23:34,327 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.1\n",
      "2025-04-24 06:23:34,328 - cellmage.chat_manager - INFO - Sending message to LLM with 9 messages in context\n",
      "2025-04-24 06:23:34,328 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 9 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Response with temperature = 0.1 =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s break down the bubble sort implementation you provided and identify the logical error.\\n\\nYou are absolutely right; the function *as written* has a critical flaw that prevents it from sorting the array at all. The fact that it might *seem* to work for the test case is likely a misunderstanding or perhaps you were expecting the correct output from a different version of the code.\\n\\n**The Logical Error:**\\n\\nThe issue lies in this line:\\n\\n```python\\narr[j], arr[j+1] = arr[j], arr[j+1]\\n```\\n\\nThis line is intended to perform a swap between `arr[j]` and `arr[j+1]` if `arr[j]` is greater than `arr[j+1]`. However, the way it\\'s written, it\\'s performing a tuple assignment where the values on the right-hand side are assigned back to the variables on the left-hand side *in their original order*.\\n\\nLet\\'s trace it:\\n1.  Python evaluates the right-hand side `(arr[j], arr[j+1])`. It gets the current values, say `(64, 34)`.\\n2.  It then assigns these values to the variables on the left-hand side `arr[j], arr[j+1]`. So, `arr[j]` gets `64` and `arr[j+1]` gets `34`.\\n\\nThe net effect is that the values are assigned back to the *same* positions they were already in. No swap actually occurs. The `if` condition `arr[j] > arr[j+1]` might be true, but the elements are never reordered.\\n\\nTherefore, the array remains completely unchanged after the function runs. The output for `[64, 34, 25, 12, 22, 11, 90]` would still be `[64, 34, 25, 12, 22, 11, 90]`.\\n\\n**The Fix:**\\n\\nTo fix this, you need to perform a proper swap. In Python, the standard and most idiomatic way to swap two variables `a` and `b` is `a, b = b, a`.\\n\\nApplying this to your array elements:\\n\\n```python\\narr[j], arr[j+1] = arr[j+1], arr[j]\\n```\\n\\nThis line correctly evaluates the right-hand side `(arr[j+1], arr[j])` (getting the values in swapped order) and then assigns them to `arr[j], arr[j+1]` (placing the smaller value at `arr[j]` and the larger at `arr[j+1]`).\\n\\n**Corrected Code:**\\n\\n```python\\ndef bubble_sort_corrected(arr):\\n    n = len(arr)\\n    # Outer loop controls the number of passes\\n    for i in range(n):\\n        # Inner loop performs comparisons and swaps\\n        # The last i elements are already in place, so we don\\'t need to compare them\\n        for j in range(0, n-i-1):\\n            # Compare adjacent elements\\n            if arr[j] > arr[j+1]:\\n                # Perform the swap using Python\\'s tuple assignment\\n                arr[j], arr[j+1] = arr[j+1], arr[j]\\n    return arr\\n\\n# Test the corrected function\\ntest_array = [64, 34, 25, 12, 22, 11, 90]\\nsorted_array = bubble_sort_corrected(test_array)\\nprint(\"Sorted array (corrected):\", sorted_array) # Output: [11, 12, 22, 25, 34, 64, 90]\\n```\\n\\n**Best Practice / Optimization:**\\n\\nWhile the above code correctly implements bubble sort, it\\'s still not optimal in the sense that it always performs `n` passes, even if the array becomes sorted earlier. A common optimization for bubble sort is to include a flag that checks if any swaps occurred during a pass. If a pass completes with no swaps, it means the array is already sorted, and we can break out of the outer loop early.\\n\\nHere\\'s the optimized version:\\n\\n```python\\ndef bubble_sort_optimized(arr):\\n    n = len(arr)\\n    # Outer loop controls the number of passes\\n    for i in range(n):\\n        # Flag to check if any swaps occurred in this pass\\n        swapped = False\\n        # Inner loop performs comparisons and swaps\\n        # The last i elements are already in place\\n        for j in range(0, n-i-1):\\n            # Compare adjacent elements\\n            if arr[j] > arr[j+1]:\\n                # Perform the swap\\n                arr[j], arr[j+1] = arr[j+1], arr[j]\\n                # Set the flag because a swap occurred\\n                swapped = True\\n\\n        # If no swaps occurred in this pass, the array is sorted\\n        if not swapped:\\n            break # Exit the outer loop early\\n\\n    return arr\\n\\n# Test the optimized function\\ntest_array_optimized = [64, 34, 25, 12, 22, 11, 90]\\nsorted_array_optimized = bubble_sort_optimized(test_array_optimized)\\nprint(\"Sorted array (optimized):\", sorted_array_optimized) # Output: [11, 12, 22, 25, 34, 64, 90]\\n\\n# Test with an already sorted array to show the optimization\\ntest_array_already_sorted = [1, 2, 3, 4, 5]\\nsorted_array_already_sorted = bubble_sort_optimized(test_array_already_sorted)\\nprint(\"Sorted array (already sorted, optimized):\", sorted_array_already_sorted) # Will exit after 1 pass\\n```\\n\\nThis optimized version is a better implementation of bubble sort as it avoids unnecessary passes over an already sorted array.\\n\\nIn summary, the primary logical error was the incorrect swap operation. Fixing that makes the algorithm work. Adding the `swapped` flag makes it more efficient in cases where the array is partially or fully sorted early in the process.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:23:51,040 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.9\n",
      "2025-04-24 06:23:51,041 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:23:51,042 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:23:51,042 - cellmage.adapters.direct_client - INFO - [Override] Setting 'top_p' = 0.95\n",
      "2025-04-24 06:23:51,043 - cellmage.chat_manager - INFO - Default persona set to 'code_expert'\n",
      "2025-04-24 06:23:51,043 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:23:51,044 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 3 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Response with temperature = 0.9 =====\n"
     ]
    }
   ],
   "source": [
    "# Set a lower temperature for precise answers\n",
    "import cellmage.integrations\n",
    "\n",
    "\n",
    "chat_manager.set_override(\"temperature\", 0.1)\n",
    "\n",
    "# Complex technical question\n",
    "tech_query = \"\"\"Explain the differences between synchronous and asynchronous programming \n",
    "                 paradigms in Python, including when to use each and their advantages \n",
    "                 and disadvantages. Include code examples.\"\"\"\n",
    "\n",
    "# Get response with low temperature\n",
    "print(\"===== Response with temperature = 0.1 =====\")\n",
    "precise_response = chat_manager.chat(tech_query, stream=False)\n",
    "\n",
    "cellmage.integrations.ipython_magic.display(precise_response)\n",
    "# Set a higher temperature for more creative answers\n",
    "chat_manager.set_override(\"temperature\", 0.9)\n",
    "\n",
    "# Clear history to get a fresh response\n",
    "chat_manager.clear_history()\n",
    "chat_manager.set_default_persona(\"code_expert\")\n",
    "\n",
    "# Get response with high temperature\n",
    "print(\"\\n===== Response with temperature = 0.9 =====\")\n",
    "creative_response = chat_manager.chat(tech_query, stream=True)\n",
    "# creative_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc58b94",
   "metadata": {},
   "source": [
    "## Testing Gemini's Contextual Understanding\n",
    "\n",
    "Let's test Gemini's ability to maintain context over a multi-turn conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6753ecf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:24:17,448 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:24:17,449 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:24:17,450 - cellmage.adapters.direct_client - INFO - [Override] Setting 'top_p' = 0.95\n",
      "2025-04-24 06:24:17,450 - cellmage.chat_manager - INFO - Default persona set to 'code_expert'\n",
      "2025-04-24 06:24:17,451 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:24:17,451 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 3 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== First Turn =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:24:32,052 - cellmage.chat_manager - INFO - Sending message to LLM with 5 messages in context\n",
      "2025-04-24 06:24:32,054 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 5 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Second Turn =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:24:46,933 - cellmage.chat_manager - INFO - Sending message to LLM with 7 messages in context\n",
      "2025-04-24 06:24:46,934 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 7 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Third Turn =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:25:08,701 - cellmage.chat_manager - INFO - Sending message to LLM with 9 messages in context\n",
      "2025-04-24 06:25:08,703 - cellmage.adapters.direct_client - INFO - Calling model 'gemini-2.5-flash' with 9 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Fourth Turn =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Okay, let\\'s implement the most common and effective optimization technique in Python for avoiding stack overflow: **Converting the Recursive Solution to an Iterative Solution**.\\n\\nWe\\'ll use the Factorial example, as it\\'s straightforward to convert.\\n\\n**Original Recursive Factorial (prone to stack overflow for large N):**\\n\\n```python\\n# (From previous example)\\n# def recursive_factorial(n):\\n#     if not isinstance(n, int) or n < 0:\\n#         raise ValueError(\"Factorial is defined for non-negative integers only\")\\n#     if n == 0:\\n#         return 1\\n#     else:\\n#         return n * recursive_factorial(n - 1)\\n```\\n\\n**Optimized Iterative Factorial (avoids stack overflow):**\\n\\n```python\\nimport sys\\n\\ndef iterative_factorial(n):\\n    \"\"\"\\n    Calculates the factorial of a non-negative integer using iteration (a loop).\\n    This avoids the risk of stack overflow for large n compared to recursion.\\n\\n    Args:\\n        n: A non-negative integer.\\n\\n    Returns:\\n        The factorial of n.\\n\\n    Raises:\\n        ValueError: If n is a negative integer.\\n    \"\"\"\\n    # --- Input Validation ---\\n    if not isinstance(n, int) or n < 0:\\n        raise ValueError(\"Factorial is defined for non-negative integers only\")\\n\\n    # --- Base Case (handled by the logic below, but explicit check is fine) ---\\n    if n == 0:\\n        return 1\\n\\n    # --- Iterative Calculation ---\\n    # Use a loop to multiply numbers from 1 up to n.\\n    # We use a variable \\'result\\' to accumulate the product.\\n    result = 1\\n    for i in range(1, n + 1): # Loop from 1 to n (inclusive)\\n        result *= i # Multiply the current result by the loop counter\\n\\n    return result\\n\\n# --- Test the function ---\\n\\nprint(\"--- Testing Iterative Factorial ---\")\\n\\n# Small number (works for both recursive and iterative)\\nsmall_n = 5\\nprint(f\"Iterative factorial({small_n}): {iterative_factorial(small_n)}\") # Output: 120\\n\\n# Large number (works for iterative, would likely cause stack overflow for recursive)\\n# Note: Python integers have arbitrary precision, so we won\\'t hit an integer overflow,\\n# but the recursive version would hit the *recursion depth* limit.\\nlarge_n = 2000 \\n\\ntry:\\n    # Check the current recursion limit (optional, just for context)\\n    # print(f\"\\\\nCurrent Python recursion limit: {sys.getrecursionlimit()}\")\\n    \\n    print(f\"\\\\nCalculating iterative factorial({large_n})...\")\\n    # This will complete successfully with the iterative version\\n    large_factorial_result = iterative_factorial(large_n)\\n    print(f\"Iterative factorial({large_n}) calculated successfully (result is very large).\")\\n    # print(f\"First 100 digits of factorial({large_n}): {str(large_factorial_result)[:100]}...\")\\n\\n    # If you were to try this with the recursive version:\\n    # print(f\"\\\\nCalculating recursive factorial({large_n})...\")\\n    # recursive_factorial(large_n) # <-- This line would likely cause RecursionError (Stack Overflow)\\n\\nexcept ValueError as e:\\n    print(f\"Error: {e}\")\\nexcept RecursionError:\\n    print(f\"Caught RecursionError! The recursive version would fail for n={large_n}.\")\\n```\\n\\n**Explanation of the Optimization:**\\n\\n1.  **Replaced Recursion with a Loop:** Instead of the function calling itself (`return n * recursive_factorial(n - 1)`), we now use a `for` loop (`for i in range(1, n + 1):`).\\n2.  **Explicit State Management:** The recursive version implicitly uses the call stack to keep track of the intermediate results (`n * ...`). The iterative version uses an explicit variable, `result`, to store the accumulated product as the loop progresses.\\n3.  **No Deep Call Stack:** Each iteration of the `for` loop runs within the *same* function call frame (`iterative_factorial`). It doesn\\'t create a new nested function call on the stack for every step. The stack depth remains constant (just the initial call to `iterative_factorial`).\\n4.  **Avoids Stack Overflow:** Because the stack depth doesn\\'t grow with the input size `n`, this iterative version can calculate the factorial of much larger numbers without hitting Python\\'s recursion depth limit.\\n\\n**Why this is effective for Factorial:**\\n\\nFactorial is a problem that can be easily broken down into a sequence of simple, repetitive steps (multiplication). An iterative approach naturally maps to this sequence. While the recursive definition is elegant, the iterative implementation is more performant and safer for large inputs in languages like Python that don\\'t optimize tail recursion.\\n\\nThis iterative conversion is a fundamental technique for transforming recursive algorithms that might cause stack issues into robust, efficient iterative ones.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clear history for a fresh conversation\n",
    "chat_manager.clear_history()\n",
    "chat_manager.set_default_persona(\"code_expert\")\n",
    "\n",
    "# Let's have a multi-turn conversation about a specific topic\n",
    "print(\"===== First Turn =====\")\n",
    "chat_manager.chat(\"What is a recursive function in programming?\", stream=False)\n",
    "\n",
    "print(\"\\n===== Second Turn =====\")\n",
    "chat_manager.chat(\"Can you give me an example using Python?\", stream=False)\n",
    "\n",
    "print(\"\\n===== Third Turn =====\")\n",
    "chat_manager.chat(\"What are some ways to optimize it to avoid stack overflow?\", stream=False)\n",
    "\n",
    "print(\"\\n===== Fourth Turn =====\")\n",
    "chat_manager.chat(\"Implement one of those optimization techniques in the example you provided.\", stream=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd43cf1",
   "metadata": {},
   "source": [
    "## Saving Multi-Turn Conversations\n",
    "\n",
    "Let's save our multi-turn conversation and see how it's stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314f8793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:25:19,439 - cellmage.storage.memory_store - INFO - Saved conversation to memory with ID: gemini_recursion_conversation\n",
      "2025-04-24 06:25:19,441 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:25:19,442 - cellmage.history_manager - INFO - Loaded conversation from gemini_recursion_conversation with 10 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to: gemini_recursion_conversation\n",
      "History cleared, current message count: 2\n",
      "Conversation loaded, message count: 10\n",
      "\n",
      "===== Loaded Conversation Summary =====\n",
      "[user] What is a recursive function in programming?\n",
      "[assistant] Okay, let's break down what a recursive function i...\n",
      "[user] Can you give me an example using Python?\n",
      "[assistant] Okay, let's look at a couple of classic examples o...\n",
      "[user] What are some ways to optimize it to avoid stack o...\n",
      "[assistant] Okay, let's talk about how to handle the risk of s...\n",
      "[user] Implement one of those optimization techniques in ...\n",
      "[assistant] Okay, let's implement the most common and effectiv...\n"
     ]
    }
   ],
   "source": [
    "# Save the conversation\n",
    "save_path = chat_manager.save_conversation(\"gemini_recursion_conversation\")\n",
    "print(f\"Conversation saved to: {save_path}\")\n",
    "\n",
    "# Clear the history\n",
    "chat_manager.clear_history()\n",
    "print(f\"History cleared, current message count: {len(chat_manager.get_history())}\")\n",
    "\n",
    "# Load the conversation back\n",
    "if save_path:\n",
    "    chat_manager.load_conversation(save_path)\n",
    "    loaded_history = chat_manager.get_history()\n",
    "    print(f\"Conversation loaded, message count: {len(loaded_history)}\")\n",
    "\n",
    "    # Display the loaded conversation summary\n",
    "    print(\"\\n===== Loaded Conversation Summary =====\")\n",
    "    for i, msg in enumerate(loaded_history):\n",
    "        if msg.role != \"system\":\n",
    "            content_preview = msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "            print(f\"[{msg.role}] {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49efc698",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the capabilities of Cellmage with the Gemini 2.5 Flash model, including:\n",
    "\n",
    "1. Setting up a Gemini model configuration\n",
    "2. Creating specialized personas\n",
    "3. Testing code generation capabilities\n",
    "4. Testing creative content generation\n",
    "5. Using code snippets to provide context\n",
    "6. Testing contextual understanding across multiple conversation turns\n",
    "7. Saving and loading multi-turn conversations\n",
    "\n",
    "The Gemini 2.5 Flash model shows strong capabilities across both technical and creative tasks within the Cellmage framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
