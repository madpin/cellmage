{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d28ed320",
   "metadata": {},
   "source": [
    "# Working with Cellmage in Jupyter Notebooks\n",
    "\n",
    "This notebook demonstrates how to interact with Cellmage directly within Jupyter notebooks using its API.\n",
    "\n",
    "**Date:** April 24, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38de57f2",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's start by setting up our environment and importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "924bc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,341 - cellmage - INFO - Cellmage logging initialized\n",
      "2025-04-24 06:21:25,344 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n",
      "2025-04-24 06:21:25,344 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Project root directory: /Users/tpinto/madpin/cellmage\n",
      "Added path: /Users/tpinto/madpin/cellmage\n",
      "Cellmage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to sys.path so we can import cellmage\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ensure the cellmage package can be imported\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added path: {project_root}\")\n",
    "\n",
    "try:\n",
    "    # Import cellmage\n",
    "    import cellmage\n",
    "\n",
    "    print(f\"Cellmage version: {cellmage.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error importing cellmage: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89387a43",
   "metadata": {},
   "source": [
    "## Understanding the Cellmage Architecture\n",
    "\n",
    "Cellmage has a modular architecture with several key components:\n",
    "\n",
    "1. **LLM Client**: Handles communication with language model providers\n",
    "2. **Persona Loader**: Manages system prompts and configurations for different personas\n",
    "3. **Snippet Provider**: Manages code snippets that can be added to conversations\n",
    "4. **History Store**: Stores conversation history\n",
    "5. **Chat Manager**: The central component that coordinates all of the above\n",
    "\n",
    "Let's set up these components for a basic workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec716de9",
   "metadata": {},
   "source": [
    "## Setting Up the LLM Client\n",
    "\n",
    "First, we'll set up the LLM client. Cellmage provides the `DirectLLMAdapter` which can connect to OpenAI, Google, Anthropic, and other LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36fc99c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,405 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_key' = sk-L...xxmA\n",
      "2025-04-24 06:21:25,405 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 06:21:25,406 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 06:21:25,406 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.7\n",
      "2025-04-24 06:21:25,405 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 06:21:25,406 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 06:21:25,406 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM client initialized.\n",
      "Temperature override set to 0.7\n"
     ]
    }
   ],
   "source": [
    "from cellmage.adapters.direct_client import DirectLLMAdapter\n",
    "\n",
    "# Create a DirectLLMAdapter with your preferred model\n",
    "# You'll need to ensure your API key is set in your environment variables\n",
    "# For example: OPENAI_API_KEY, GOOGLE_API_KEY, etc.\n",
    "llm_client = DirectLLMAdapter(default_model=\"gpt-4.1-nano\")\n",
    "\n",
    "print(\"LLM client initialized.\")\n",
    "\n",
    "# Optional: Set parameter overrides\n",
    "llm_client.set_override(\"temperature\", 0.7)\n",
    "print(f\"Temperature override set to 0.7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21e45c7",
   "metadata": {},
   "source": [
    "## Creating Personas\n",
    "\n",
    "Personas define the behavior of the LLM through system prompts and parameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e4c713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,446 - cellmage.resources.memory_loader - INFO - Added persona 'python_expert' to memory\n",
      "2025-04-24 06:21:25,447 - cellmage.resources.memory_loader - INFO - Added persona 'creative_writer' to memory\n",
      "2025-04-24 06:21:25,447 - cellmage.resources.memory_loader - INFO - Added persona 'creative_writer' to memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available personas: ['creative_writer', 'python_expert']\n"
     ]
    }
   ],
   "source": [
    "from cellmage.resources.memory_loader import MemoryLoader\n",
    "\n",
    "# Create a memory-based persona loader\n",
    "persona_loader = MemoryLoader()\n",
    "\n",
    "# Create a persona for Python code assistance\n",
    "persona_loader.add_persona(\n",
    "    name=\"python_expert\",\n",
    "    system_message=\"You are a Python programming expert who provides clean, efficient code examples with clear explanations. Focus on best practices and modern Python features.\",\n",
    "    config={\"temperature\": 0.3},\n",
    ")\n",
    "\n",
    "# Create a persona for creative writing\n",
    "persona_loader.add_persona(\n",
    "    name=\"creative_writer\",\n",
    "    system_message=\"You are a creative writing assistant who helps craft engaging stories and narratives. Be imaginative and provide vivid, descriptive content.\",\n",
    "    config={\"temperature\": 0.8},\n",
    ")\n",
    "\n",
    "# List available personas\n",
    "personas = persona_loader.list_personas()\n",
    "print(f\"Available personas: {personas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de524e32",
   "metadata": {},
   "source": [
    "## Managing Code Snippets\n",
    "\n",
    "Snippets are useful for providing additional context to the LLM. We can reuse our persona loader to manage snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a94ad44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,453 - cellmage.resources.memory_loader - INFO - Added snippet 'fibonacci_recursive' to memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available snippets: ['fibonacci_recursive']\n"
     ]
    }
   ],
   "source": [
    "# We can use the same MemoryLoader for snippets\n",
    "snippet_provider = MemoryLoader()\n",
    "\n",
    "# Create a sample code snippet\n",
    "snippet_provider.add_snippet(\n",
    "    name=\"fibonacci_recursive\",\n",
    "    content=\"\"\"```python\n",
    "def calculate_fibonacci(n):\n",
    "    \"\"Calculate the nth Fibonacci number.\"\"\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)\n",
    "    \n",
    "# Test the function\n",
    "result = calculate_fibonacci(10)\n",
    "print(f\"The 10th Fibonacci number is: {result}\")\n",
    "```\"\"\",\n",
    ")\n",
    "\n",
    "# List available snippets\n",
    "snippets = snippet_provider.list_snippets()\n",
    "print(f\"Available snippets: {snippets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c029179",
   "metadata": {},
   "source": [
    "## Setting Up the Chat Manager\n",
    "\n",
    "Now we'll set up the ChatManager which coordinates all the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e09ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,462 - cellmage.chat_manager - INFO - Initializing ChatManager\n",
      "2025-04-24 06:21:25,463 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n",
      "2025-04-24 06:21:25,463 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 06:21:25,463 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:21:25,464 - cellmage.chat_manager - INFO - Default persona set to 'python_expert'\n",
      "2025-04-24 06:21:25,463 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n",
      "2025-04-24 06:21:25,463 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 06:21:25,463 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:21:25,464 - cellmage.chat_manager - INFO - Default persona set to 'python_expert'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat manager initialized with 'python_expert' persona.\n"
     ]
    }
   ],
   "source": [
    "from cellmage.storage.memory_store import MemoryStore\n",
    "\n",
    "# Create a memory-based history store\n",
    "history_store = MemoryStore()\n",
    "\n",
    "# Create the chat manager\n",
    "chat_manager = cellmage.ChatManager(\n",
    "    llm_client=llm_client,\n",
    "    persona_loader=persona_loader,\n",
    "    snippet_provider=snippet_provider,\n",
    "    history_store=history_store,\n",
    ")\n",
    "\n",
    "# Set default persona\n",
    "chat_manager.set_default_persona(\"python_expert\")\n",
    "print(\"Chat manager initialized with 'python_expert' persona.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364d5a8",
   "metadata": {},
   "source": [
    "## Basic LLM Interaction\n",
    "\n",
    "Now that we have all components set up, let's interact with the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9afa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,541 - cellmage.chat_manager - INFO - Sending message to LLM with 2 messages in context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Explain the concept of list comprehensions in Python with a few examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:25,549 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 2 messages\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "Certainly! \n",
       "\n",
       "**List comprehensions** in Python provide a concise way to create lists. They allow you to generate new lists by applying an expression to each item in an existing iterable (like a list, range, etc.), optionally filtering items with a condition.\n",
       "\n",
       "### Basic syntax:\n",
       "```python\n",
       "[expression for item in iterable if condition]\n",
       "```\n",
       "\n",
       "- `expression`: The value to store in the new list.\n",
       "- `item`: The variable representing each element in the iterable.\n",
       "- `iterable`: The collection you're iterating over.\n",
       "- `condition` (optional): A predicate that filters items.\n",
       "\n",
       "---\n",
       "\n",
       "### Examples\n",
       "\n",
       "#### 1. Creating a list of squares\n",
       "```python\n",
       "squares = [x**2 for x in range(5)]\n",
       "print(squares)  # Output: [0, 1, 4, 9, 16]\n",
       "```\n",
       "\n",
       "#### 2. Filtering items\n",
       "Suppose you want only even numbers from 0 to 9:\n",
       "```python\n",
       "evens = [x for x in range(10) if x % 2 == 0]\n",
       "print(evens)  # Output: [0, 2, 4, 6, 8]\n",
       "```\n",
       "\n",
       "#### 3. Applying a function\n",
       "Convert a list of strings to their uppercase versions:\n",
       "```python\n",
       "words = ['apple', 'banana', 'cherry']\n",
       "uppercase_words = [word.upper() for word in words]\n",
       "print(uppercase_words)  # Output: ['APPLE', 'BANANA', 'CHERRY']\n",
       "```\n",
       "\n",
       "#### 4. Nested list comprehensions\n",
       "Create a multiplication table (e.g., 1 to 3):\n",
       "```python\n",
       "table = [[i * j for j in range(1, 4)] for i in range(1, 4)]\n",
       "print(table)\n",
       "# Output: [[1, 2, 3], [2, 4, 6], [3, 6, 9]]\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "### Benefits\n",
       "- More concise and readable than traditional loops.\n",
       "- Often faster due to internal optimizations.\n",
       "\n",
       "### Summary\n",
       "List comprehensions are a powerful feature for creating and transforming lists efficiently and cleanly in Python."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display function for better visualization of responses\n",
    "def display_response(content):\n",
    "    display(Markdown(f\"**Assistant:**\\n{content}\"))\n",
    "\n",
    "\n",
    "# Send a message to the LLM\n",
    "prompt = \"Explain the concept of list comprehensions in Python with a few examples.\"\n",
    "print(f\"User: {prompt}\")\n",
    "\n",
    "# Get response (stream=False for simplicity)\n",
    "response = chat_manager.chat(prompt, stream=False)\n",
    "\n",
    "# Display the response\n",
    "display_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e6e26",
   "metadata": {},
   "source": [
    "## Using a Different Persona\n",
    "\n",
    "We can switch personas for different types of interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1578bb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:28,758 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.8\n",
      "2025-04-24 06:21:28,758 - cellmage.chat_manager - INFO - Default persona set to 'creative_writer'\n",
      "2025-04-24 06:21:28,759 - cellmage.chat_manager - INFO - Sending message to LLM with 4 messages in context\n",
      "2025-04-24 06:21:28,760 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 4 messages\n",
      "2025-04-24 06:21:28,758 - cellmage.chat_manager - INFO - Default persona set to 'creative_writer'\n",
      "2025-04-24 06:21:28,759 - cellmage.chat_manager - INFO - Sending message to LLM with 4 messages in context\n",
      "2025-04-24 06:21:28,760 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 4 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to 'creative_writer' persona.\n",
      "User: Write a short poem about coding in Python.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "In lines of Python, magic starts,  \n",
       "A world of logic, crafted with arts.  \n",
       "Indentations dance, clean and bright,  \n",
       "Turning thoughts to code in gentle light.\n",
       "\n",
       "Variables whisper, functions sing,  \n",
       "Loops and conditions in harmony bring,  \n",
       "A tapestry woven with every line,  \n",
       "Python's poetry, elegant and fine."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the active persona\n",
    "chat_manager.set_default_persona(\"creative_writer\")\n",
    "print(\"Switched to 'creative_writer' persona.\")\n",
    "\n",
    "# Send a creative writing prompt\n",
    "creative_prompt = \"Write a short poem about coding in Python.\"\n",
    "print(f\"User: {creative_prompt}\")\n",
    "\n",
    "# Get response\n",
    "creative_response = chat_manager.chat(creative_prompt, stream=False)\n",
    "\n",
    "# Display the response\n",
    "display_response(creative_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ae670",
   "metadata": {},
   "source": [
    "## Using Snippets for Context\n",
    "\n",
    "We can add snippets to provide context before our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "934e40ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:29,636 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.3\n",
      "2025-04-24 06:21:29,636 - cellmage.chat_manager - INFO - Default persona set to 'python_expert'\n",
      "2025-04-24 06:21:29,637 - cellmage.history_manager - INFO - History cleared. Kept 1 system messages.\n",
      "2025-04-24 06:21:29,638 - cellmage.chat_manager - INFO - Added snippet 'fibonacci_recursive' as system message\n",
      "2025-04-24 06:21:29,638 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:29,638 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n",
      "2025-04-24 06:21:29,636 - cellmage.chat_manager - INFO - Default persona set to 'python_expert'\n",
      "2025-04-24 06:21:29,637 - cellmage.history_manager - INFO - History cleared. Kept 1 system messages.\n",
      "2025-04-24 06:21:29,638 - cellmage.chat_manager - INFO - Added snippet 'fibonacci_recursive' as system message\n",
      "2025-04-24 06:21:29,638 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:29,638 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to 'python_expert' persona.\n",
      "History cleared.\n",
      "Added 'fibonacci_recursive' snippet to the conversation.\n",
      "User: The recursive Fibonacci implementation is inefficient. Please provide an optimized version using dynamic programming and explain the performance improvement.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "Certainly! The recursive implementation of Fibonacci has exponential time complexity because it recalculates the same subproblems multiple times. To optimize this, we can use **dynamic programming**—either with memoization (top-down) or tabulation (bottom-up)—to store previously computed results and avoid redundant calculations.\n",
       "\n",
       "Here's an efficient, iterative (bottom-up) implementation using a list to store intermediate results:\n",
       "\n",
       "```python\n",
       "def calculate_fibonacci(n):\n",
       "    \"\"\"Calculate the nth Fibonacci number using dynamic programming (bottom-up approach).\"\"\"\n",
       "    if n <= 0:\n",
       "        return 0\n",
       "    elif n == 1:\n",
       "        return 1\n",
       "\n",
       "    fib = [0] * (n + 1)\n",
       "    fib[1] = 1\n",
       "\n",
       "    for i in range(2, n + 1):\n",
       "        fib[i] = fib[i - 1] + fib[i - 2]\n",
       "\n",
       "    return fib[n]\n",
       "\n",
       "# Test the function\n",
       "result = calculate_fibonacci(10)\n",
       "print(f\"The 10th Fibonacci number is: {result}\")\n",
       "```\n",
       "\n",
       "### Performance Improvement:\n",
       "- **Time Complexity:** O(n), since each Fibonacci number up to `n` is computed exactly once.\n",
       "- **Space Complexity:** O(n), due to the list storing all intermediate Fibonacci numbers. This can be optimized further to O(1) space if needed.\n",
       "\n",
       "### Optimized Space Version:\n",
       "If you only need the `n`th Fibonacci number without storing the entire sequence:\n",
       "\n",
       "```python\n",
       "def calculate_fibonacci(n):\n",
       "    \"\"\"Calculate the nth Fibonacci number using constant space.\"\"\"\n",
       "    if n <= 0:\n",
       "        return 0\n",
       "    elif n == 1:\n",
       "        return 1\n",
       "\n",
       "    prev, curr = 0, 1\n",
       "    for _ in range(2, n + 1):\n",
       "        prev, curr = curr, prev + curr\n",
       "\n",
       "    return curr\n",
       "\n",
       "# Test the function\n",
       "result = calculate_fibonacci(10)\n",
       "print(f\"The 10th Fibonacci number is: {result}\")\n",
       "```\n",
       "\n",
       "This version maintains only two variables, making it more space-efficient while still running in linear time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Switch back to python_expert persona\n",
    "chat_manager.set_default_persona(\"python_expert\")\n",
    "print(\"Switched to 'python_expert' persona.\")\n",
    "\n",
    "# Clear history for a clean conversation\n",
    "chat_manager.clear_history()\n",
    "print(\"History cleared.\")\n",
    "\n",
    "# Add the snippet to the conversation\n",
    "chat_manager.add_snippet(\"fibonacci_recursive\")\n",
    "print(\"Added 'fibonacci_recursive' snippet to the conversation.\")\n",
    "\n",
    "# Send a query about the snippet\n",
    "snippet_query = \"The recursive Fibonacci implementation is inefficient. Please provide an optimized version using dynamic programming and explain the performance improvement.\"\n",
    "print(f\"User: {snippet_query}\")\n",
    "\n",
    "# Get response\n",
    "snippet_response = chat_manager.chat(snippet_query, stream=False)\n",
    "\n",
    "# Display the response\n",
    "display_response(snippet_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd21c3",
   "metadata": {},
   "source": [
    "## Adjusting Parameters for a Single Query\n",
    "\n",
    "We can override parameters for specific queries using the `chat()` method directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bdb86f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:32,357 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:21:32,358 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:32,358 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n",
      "2025-04-24 06:21:32,358 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:32,358 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History cleared.\n",
      "User: Generate three creative ways to explain recursion to a 10-year-old.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "Sure! Here are three fun and creative ways to explain recursion to a 10-year-old:\n",
       "\n",
       "### 1. **The Russian Nesting Dolls**\n",
       "Imagine you have a set of beautiful dolls called nesting dolls. When you open one doll, you find a smaller doll inside. If you open that smaller doll, there's an even smaller one inside, and so on, until you reach the tiniest doll which doesn't open at all.\n",
       "\n",
       "**Recursion** is like opening these dolls: **each time you open a doll, you're doing the same action (opening), but with a smaller doll**. The process continues until you reach the smallest doll, which is the **base case**—the point where you stop opening more dolls.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. **The Infinite Mirror Reflection**\n",
       "Picture standing between two mirrors facing each other. When you look into the mirrors, you see a series of your reflection repeating over and over again, each one smaller than the last.\n",
       "\n",
       "**Recursion** is like that: a process that repeats itself, each time getting closer to a final, smallest image (the base case). When the reflection gets too small, you decide to stop, just like when a recursive function stops calling itself.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. **Climbing Down a Stairs with a Puzzle**\n",
       "Imagine you're climbing down a staircase, and at each step, there's a small puzzle you need to solve before you can go down to the next step.\n",
       "\n",
       "**Recursion** is like solving one small puzzle at each step: you solve the first puzzle, then move to the next. When you reach the bottom step (the base case), you're done. The process of solving each puzzle is the same, just like the recursive function calls itself at a smaller problem each time.\n",
       "\n",
       "---\n",
       "\n",
       "Would you like a simple code example to go with one of these explanations?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear history for a clean conversation\n",
    "chat_manager.clear_history()\n",
    "print(\"History cleared.\")\n",
    "\n",
    "# Send a query with a high temperature for more creative responses\n",
    "custom_query = \"Generate three creative ways to explain recursion to a 10-year-old.\"\n",
    "print(f\"User: {custom_query}\")\n",
    "\n",
    "# Get response with a custom temperature\n",
    "custom_response = chat_manager.chat(\n",
    "    custom_query,\n",
    "    stream=False,\n",
    "    temperature=0.9,  # Override temperature just for this query\n",
    ")\n",
    "\n",
    "# Display the response\n",
    "display_response(custom_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7578983e",
   "metadata": {},
   "source": [
    "## Managing Conversation History\n",
    "\n",
    "Let's examine the conversation history and how to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a02acee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current history has 4 messages.\n",
      "1. SYSTEM: You are a Python programming expert who provides c...\n",
      "2. SYSTEM: ```python\n",
      "def calculate_fibonacci(n):\n",
      "    \"\"Calcul...\n",
      "3. USER: Generate three creative ways to explain recursion ...\n",
      "4. ASSISTANT: Sure! Here are three fun and creative ways to expl...\n"
     ]
    }
   ],
   "source": [
    "# Get the current history\n",
    "history = chat_manager.get_history()\n",
    "print(f\"Current history has {len(history)} messages.\")\n",
    "\n",
    "# Display each message in the history\n",
    "for i, message in enumerate(history):\n",
    "    role = message.role.upper()\n",
    "    content_preview = message.content[:50] + \"...\" if len(message.content) > 50 else message.content\n",
    "    print(f\"{i + 1}. {role}: {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32563595",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversation\n",
    "\n",
    "Let's have a multi-turn conversation to test the context retention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9505b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:34,695 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:21:34,696 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:34,698 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n",
      "2025-04-24 06:21:34,696 - cellmage.chat_manager - INFO - Sending message to LLM with 3 messages in context\n",
      "2025-04-24 06:21:34,698 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History cleared.\n",
      "\n",
      "--- First Turn ---\n",
      "User: What is a decorator in Python?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "A decorator in Python is a design pattern that allows you to modify or enhance the behavior of functions or classes **without changing their actual code**. Decorators are applied using the `@decorator_name` syntax above a function or class definition.\n",
       "\n",
       "**In simple terms:**\n",
       "- Think of a decorator as a wrapper around a function.\n",
       "- It takes a function as input, adds some functionality, and returns a new function.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "```python\n",
       "def my_decorator(func):\n",
       "    def wrapper():\n",
       "        print(\"Before the function runs\")\n",
       "        func()\n",
       "        print(\"After the function runs\")\n",
       "    return wrapper\n",
       "\n",
       "@my_decorator\n",
       "def say_hello():\n",
       "    print(\"Hello!\")\n",
       "\n",
       "say_hello()\n",
       "```\n",
       "\n",
       "**Output:**\n",
       "```\n",
       "Before the function runs\n",
       "Hello!\n",
       "After the function runs\n",
       "```\n",
       "\n",
       "**Key points:**\n",
       "- Decorators are often used for logging, access control, timing, or modifying input/output.\n",
       "- They are a powerful feature for writing clean, reusable, and expressive code."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:37,968 - cellmage.chat_manager - INFO - Sending message to LLM with 5 messages in context\n",
      "2025-04-24 06:21:37,969 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 5 messages\n",
      "2025-04-24 06:21:37,969 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 5 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Second Turn ---\n",
      "User: Can you show me a simple example of a timing decorator?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "Certainly! Here's a simple example of a timing decorator that measures how long a function takes to execute:\n",
       "\n",
       "```python\n",
       "import time\n",
       "\n",
       "def timing_decorator(func):\n",
       "    def wrapper(*args, **kwargs):\n",
       "        start_time = time.time()  # Record start time\n",
       "        result = func(*args, **kwargs)  # Call the original function\n",
       "        end_time = time.time()  # Record end time\n",
       "        duration = end_time - start_time\n",
       "        print(f\"{func.__name__} took {duration:.4f} seconds to execute.\")\n",
       "        return result\n",
       "    return wrapper\n",
       "\n",
       "@timing_decorator\n",
       "def example_function(n):\n",
       "    total = 0\n",
       "    for i in range(n):\n",
       "        total += i\n",
       "    return total\n",
       "\n",
       "# Call the decorated function\n",
       "result = example_function(10**6)\n",
       "print(f\"Result: {result}\")\n",
       "```\n",
       "\n",
       "**Explanation:**\n",
       "- The `timing_decorator` wraps any function to measure its execution time.\n",
       "- `*args` and `**kwargs` allow it to work with functions of any signature.\n",
       "- It prints the duration after the function completes.\n",
       "\n",
       "**When you run this code, you'll see output similar to:**\n",
       "\n",
       "```\n",
       "example_function took 0.0456 seconds to execute.\n",
       "Result: 499999500000\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:43,324 - cellmage.chat_manager - INFO - Sending message to LLM with 7 messages in context\n",
      "2025-04-24 06:21:43,326 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 7 messages\n",
      "2025-04-24 06:21:43,326 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 7 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Third Turn ---\n",
      "User: How would I modify this decorator to also log the function name?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "To include the function name in the log, you can access `func.__name__` inside the decorator. Here's the modified version:\n",
       "\n",
       "```python\n",
       "import time\n",
       "\n",
       "def timing_decorator(func):\n",
       "    def wrapper(*args, **kwargs):\n",
       "        start_time = time.time()\n",
       "        result = func(*args, **kwargs)\n",
       "        end_time = time.time()\n",
       "        duration = end_time - start_time\n",
       "        print(f\"Function '{func.__name__}' took {duration:.4f} seconds to execute.\")\n",
       "        return result\n",
       "    return wrapper\n",
       "\n",
       "@timing_decorator\n",
       "def example_function(n):\n",
       "    total = 0\n",
       "    for i in range(n):\n",
       "        total += i\n",
       "    return total\n",
       "\n",
       "# Call the decorated function\n",
       "result = example_function(10**6)\n",
       "print(f\"Result: {result}\")\n",
       "```\n",
       "\n",
       "**Output:**\n",
       "\n",
       "```\n",
       "Function 'example_function' took 0.0456 seconds to execute.\n",
       "Result: 499999500000\n",
       "```\n",
       "\n",
       "**Summary:**\n",
       "- Using `func.__name__` inside the decorator allows you to dynamically include the function's name in your logs, making it clearer which function's timing is being reported."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear history for a clean conversation\n",
    "chat_manager.clear_history()\n",
    "print(\"History cleared.\\n\")\n",
    "\n",
    "# First turn\n",
    "print(\"--- First Turn ---\")\n",
    "print(\"User: What is a decorator in Python?\")\n",
    "response1 = chat_manager.chat(\"What is a decorator in Python?\", stream=False)\n",
    "display_response(response1)\n",
    "\n",
    "# Second turn\n",
    "print(\"\\n--- Second Turn ---\")\n",
    "print(\"User: Can you show me a simple example of a timing decorator?\")\n",
    "response2 = chat_manager.chat(\"Can you show me a simple example of a timing decorator?\", stream=False)\n",
    "display_response(response2)\n",
    "\n",
    "# Third turn\n",
    "print(\"\\n--- Third Turn ---\")\n",
    "print(\"User: How would I modify this decorator to also log the function name?\")\n",
    "response3 = chat_manager.chat(\"How would I modify this decorator to also log the function name?\", stream=False)\n",
    "display_response(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286e2c0",
   "metadata": {},
   "source": [
    "## Saving and Loading Conversations\n",
    "\n",
    "Cellmage allows you to save and load conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f320f7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:45,129 - cellmage.storage.memory_store - INFO - Saved conversation to memory with ID: decorator_conversation\n",
      "2025-04-24 06:21:45,131 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:21:45,132 - cellmage.history_manager - INFO - Loaded conversation from decorator_conversation with 8 messages\n",
      "2025-04-24 06:21:45,131 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:21:45,132 - cellmage.history_manager - INFO - Loaded conversation from decorator_conversation with 8 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to: decorator_conversation\n",
      "History cleared, current message count: 2\n",
      "Conversation loaded, message count: 8\n",
      "\n",
      "=== Loaded Conversation Summary ===\n",
      "USER: What is a decorator in Python?\n",
      "ASSISTANT: A decorator in Python is a design pattern that all...\n",
      "USER: Can you show me a simple example of a timing decor...\n",
      "ASSISTANT: Certainly! Here's a simple example of a timing dec...\n",
      "USER: How would I modify this decorator to also log the ...\n",
      "ASSISTANT: To include the function name in the log, you can a...\n"
     ]
    }
   ],
   "source": [
    "# Save the current conversation\n",
    "save_path = chat_manager.save_conversation(\"decorator_conversation\")\n",
    "print(f\"Conversation saved to: {save_path}\")\n",
    "\n",
    "# Clear history\n",
    "chat_manager.clear_history()\n",
    "print(f\"History cleared, current message count: {len(chat_manager.get_history())}\")\n",
    "\n",
    "# Load the saved conversation\n",
    "chat_manager.load_conversation(save_path)\n",
    "print(f\"Conversation loaded, message count: {len(chat_manager.get_history())}\")\n",
    "\n",
    "# Display the loaded conversation summary\n",
    "print(\"\\n=== Loaded Conversation Summary ===\")\n",
    "history = chat_manager.get_history()\n",
    "for i, message in enumerate(history):\n",
    "    if message.role != \"system\":\n",
    "        role = message.role.upper()\n",
    "        content_preview = message.content[:50] + \"...\" if len(message.content) > 50 else message.content\n",
    "        print(f\"{role}: {content_preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15e27eb",
   "metadata": {},
   "source": [
    "## Parameter Overrides\n",
    "\n",
    "We can set and manage parameter overrides for the LLM client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee73ce74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:45,146 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.5\n",
      "2025-04-24 06:21:45,149 - cellmage.adapters.direct_client - INFO - [Override] Setting 'max_tokens' = 2000\n",
      "2025-04-24 06:21:45,150 - cellmage.adapters.direct_client - INFO - [Override] Removed 'max_tokens'\n",
      "2025-04-24 06:21:45,152 - cellmage.adapters.direct_client - INFO - [Override] All instance overrides cleared.\n",
      "2025-04-24 06:21:45,149 - cellmage.adapters.direct_client - INFO - [Override] Setting 'max_tokens' = 2000\n",
      "2025-04-24 06:21:45,150 - cellmage.adapters.direct_client - INFO - [Override] Removed 'max_tokens'\n",
      "2025-04-24 06:21:45,152 - cellmage.adapters.direct_client - INFO - [Override] All instance overrides cleared.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter overrides set: temperature=0.5, max_tokens=2000\n",
      "Current overrides: {}\n",
      "Removed 'max_tokens' override\n",
      "Updated overrides: {}\n",
      "All overrides cleared\n",
      "Final overrides: {}\n"
     ]
    }
   ],
   "source": [
    "# Set parameter overrides directly on the LLM client\n",
    "llm_client.set_override(\"temperature\", 0.5)\n",
    "llm_client.set_override(\"max_tokens\", 2000)\n",
    "print(\"Parameter overrides set: temperature=0.5, max_tokens=2000\")\n",
    "\n",
    "# Check current overrides - this accesses the llm_client directly since\n",
    "# ChatManager might not have a get_overrides method\n",
    "# Try to get overrides safely\n",
    "try:\n",
    "    if hasattr(chat_manager, \"get_overrides\"):\n",
    "        # Use the method if available\n",
    "        overrides = chat_manager.get_overrides()\n",
    "    else:\n",
    "        # Access the overrides directly from the llm_client\n",
    "        overrides = llm_client._overrides if hasattr(llm_client, \"_overrides\") else {}\n",
    "    print(f\"Current overrides: {overrides}\")\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't retrieve overrides: {e}\")\n",
    "\n",
    "# Remove a specific override\n",
    "llm_client.remove_override(\"max_tokens\")\n",
    "print(\"Removed 'max_tokens' override\")\n",
    "\n",
    "# Check updated overrides\n",
    "try:\n",
    "    overrides = llm_client._overrides if hasattr(llm_client, \"_overrides\") else {}\n",
    "    print(f\"Updated overrides: {overrides}\")\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't retrieve overrides: {e}\")\n",
    "\n",
    "# Clear all overrides\n",
    "llm_client.clear_overrides()\n",
    "print(\"All overrides cleared\")\n",
    "\n",
    "# Check final overrides\n",
    "try:\n",
    "    overrides = llm_client._overrides if hasattr(llm_client, \"_overrides\") else {}\n",
    "    print(f\"Final overrides: {overrides}\")\n",
    "except Exception as e:\n",
    "    print(f\"Couldn't retrieve overrides: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eba0ba",
   "metadata": {},
   "source": [
    "## Handling Common Issues with Magic Functions\n",
    "\n",
    "Here are some common issues you might encounter when using Cellmage's magic functions and how to resolve them:\n",
    "\n",
    "1. **Magic command not found** - Make sure you've loaded the extension with `%load_ext cellmage`\n",
    "2. **API connection errors** - Check your API key and connection settings\n",
    "3. **Missing personas or snippets** - Use `--list-personas` or `--list-snippets` to check available resources\n",
    "4. **Memory errors** - Try clearing history with `--clear-history` to free up memory\n",
    "5. **Import errors** - Verify the cellmage package is correctly installed and in your Python path\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the key features of Cellmage's IPython magic functions, including:\n",
    "\n",
    "1. Loading the cellmage extension\n",
    "2. Managing personas and LLM parameters\n",
    "3. Working with code snippets\n",
    "4. Interacting with the LLM using `%%llm` cell magic\n",
    "5. Managing conversation history\n",
    "6. Saving and loading conversations\n",
    "7. Understanding the underlying implementation\n",
    "\n",
    "These magic functions make it easy to integrate LLMs directly into your notebook workflow, enhancing your productivity when working with AI assistants."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
