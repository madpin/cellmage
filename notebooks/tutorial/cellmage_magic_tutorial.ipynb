{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd05eb23",
   "metadata": {},
   "source": [
    "# CellMage Magic Functions Tutorial\n",
    "\n",
    "This notebook demonstrates how to use CellMage's powerful magic functions to interact with LLMs directly within your Jupyter notebooks.\n",
    "\n",
    "**Date:** April 24, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc7e2ce",
   "metadata": {},
   "source": [
    "## 1. Getting Started with CellMage\n",
    "\n",
    "CellMage provides intuitive IPython magic functions that allow you to interact with Large Language Models without leaving your notebook environment. Let's start by loading the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed3f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CellMage extension\n",
    "%load_ext cellmage\n",
    "\n",
    "# Display version information\n",
    "import cellmage\n",
    "\n",
    "print(f\"CellMage version: {cellmage.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bc60f",
   "metadata": {},
   "source": [
    "## 2. Configuring CellMage with `%llm_config`\n",
    "\n",
    "The `%llm_config` (or equivalently, `%llm_setup`) magic command allows you to configure CellMage's behavior, including setting the default model, selecting personas, and managing conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14aa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic configuration\n",
    "%llm_config --status\n",
    "\n",
    "# You can set the default LLM model\n",
    "# %llm_config --default_model gpt-4o\n",
    "\n",
    "# List available personas\n",
    "%llm_config --list-personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492569",
   "metadata": {},
   "source": [
    "### Setting API Credentials\n",
    "\n",
    "To connect to LLM services, you need to provide API credentials. While we recommend using environment variables, you can also set these directly in your notebook:\n",
    "\n",
    "```python\n",
    "%llm_config --api_key \"your-api-key\" --api_base \"https://api.example.com/v1\"\n",
    "```\n",
    "\n",
    "⚠️ **Security Warning**: Never commit notebooks with API keys to version control!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02578cda",
   "metadata": {},
   "source": [
    "## 3. Using the `%%llm` Cell Magic\n",
    "\n",
    "The core functionality of CellMage is the `%%llm` cell magic. Simply add this to the top of any cell, and the cell's content will be sent as a prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f040f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Explain the concept of a Jupyter notebook to someone new to data science in 2-3 paragraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de8731",
   "metadata": {},
   "source": [
    "### Using Options with `%%llm`\n",
    "\n",
    "You can customize the behavior of individual LLM interactions by passing options to the `%%llm` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm --model gpt-3.5-turbo --temperature 0.8 --no-stream\n",
    "Write a haiku about programming in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5a05c",
   "metadata": {},
   "source": [
    "## 4. Working with Personas\n",
    "\n",
    "Personas are predefined configurations that include system prompts and LLM parameters. They help you quickly switch between different interaction styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e95b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the --persona option to switch personas for a specific query\n",
    "%%llm --persona python_expert\n",
    "Explain how decorators work in Python with a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default persona for all subsequent interactions\n",
    "%llm_config --persona creative_writer\n",
    "%llm_config --show-persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Write a short poem about artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93190aee",
   "metadata": {},
   "source": [
    "## 5. Managing Conversation History\n",
    "\n",
    "CellMage automatically maintains conversation history to provide context for your interactions. You can manage this history using various commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1117bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the current conversation history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the conversation history\n",
    "%llm_config --clear-history\n",
    "\n",
    "# Verify that the history is cleared\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca7367",
   "metadata": {},
   "source": [
    "### Automatic Rollback\n",
    "\n",
    "One of CellMage's most useful features is automatic rollback. When you re-run a cell that contains `%%llm`, CellMage automatically removes the previous interaction from that cell from the history. This prevents duplication when you're iterating on your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Explain what 'automatic rollback' means in the context of CellMage.\n",
    "\n",
    "# Try running this cell multiple times - CellMage will roll back the previous response!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe1df1",
   "metadata": {},
   "source": [
    "## 6. Using Snippets\n",
    "\n",
    "Snippets allow you to include code or other content as context in your LLM conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b25ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a sample code snippet first\n",
    "%%writefile /tmp/example_code.py\n",
    "\n",
    "\n",
    "def process_data(data_list):\n",
    "    \"\"\"Process a list of numeric data.\"\"\"\n",
    "    results = []\n",
    "    for item in data_list:\n",
    "        if isinstance(item, (int, float)):\n",
    "            results.append(item * 2)\n",
    "        else:\n",
    "            print(f\"Skipping non-numeric item: {item}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_data = [1, 2, \"3\", 4.5, \"text\"]\n",
    "processed = process_data(sample_data)\n",
    "print(f\"Processed data: {processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780b652",
   "metadata": {},
   "source": [
    "Now we can list available snippets and add one to our conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70647b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available snippets\n",
    "%llm_config --list-snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our file as a snippet\n",
    "%llm_config --snippets /tmp/example_code.py system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a11de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm --persona python_expert\n",
    "Review the code I provided. How could I improve the error handling and make the function more robust?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c12c7",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Conversations\n",
    "\n",
    "CellMage allows you to save your conversation history and load it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current conversation\n",
    "%llm_config --save code_review_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear history\n",
    "%llm_config --clear-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available saved sessions\n",
    "%llm_config --list-sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290836ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved session\n",
    "%llm_config --load code_review_session\n",
    "\n",
    "# Show the loaded history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40607d",
   "metadata": {},
   "source": [
    "## 8. Using Parameter Overrides\n",
    "\n",
    "You can temporarily override LLM parameters for specific interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a parameter override\n",
    "%llm_config --set-override temperature 0.9\n",
    "\n",
    "# Show current overrides\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22af50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Generate three creative startup ideas combining artificial intelligence and sustainable energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205edb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all overrides\n",
    "%llm_config --clear-overrides\n",
    "\n",
    "# Verify overrides are cleared\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d8eb0",
   "metadata": {},
   "source": [
    "## 9. Ambient Mode with `%llm_setup_forever`\n",
    "\n",
    "For a pure chat experience, you can enable \"Ambient Enchantment\" mode, which treats all regular code cells as prompts for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable ambient mode\n",
    "%llm_setup_forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regular cell will be treated as a prompt for the LLM\n",
    "What are three best practices for writing clean, maintainable Python code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable ambient mode when you're done\n",
    "%disable_llm_setup_forever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e9ceb",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting and Tips\n",
    "\n",
    "Here are some common issues and how to resolve them:\n",
    "\n",
    "1. **Magic commands not found**: Make sure you've loaded the extension with `%load_ext cellmage`\n",
    "2. **API connection errors**: Check your API key and connection settings\n",
    "3. **Missing personas or snippets**: Use `--list-personas` or `--list-snippets` to check available resources\n",
    "4. **Memory errors**: Try clearing history with `--clear-history` to free up memory\n",
    "5. **Import errors**: Verify the CellMage package is correctly installed in your Python path\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Use `--no-stream` for non-interactive tasks to get the full response at once\n",
    "- Keep conversation history concise for faster responses\n",
    "- Choose appropriate models for your task (smaller models for simple tasks, larger models for complex reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ace29",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "CellMage's magic functions provide a seamless way to integrate LLM capabilities directly into your Jupyter workflow. By using these magic commands, you can:\n",
    "\n",
    "- Interact with LLMs without leaving your notebook\n",
    "- Maintain conversation context across cells\n",
    "- Customize LLM behavior with personas and parameter settings\n",
    "- Save and load conversations for later use\n",
    "- Provide additional context through snippets\n",
    "\n",
    "This makes CellMage a powerful tool for data scientists, researchers, and developers who want to leverage LLMs in their workflow.\n",
    "\n",
    "Happy conjuring! ✨🧙‍♂️"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
