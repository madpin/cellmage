{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fa1ce7a",
   "metadata": {},
   "source": [
    "# Introduction to Cellmage\n",
    "\n",
    "This notebook introduces the basic functionality of the `cellmage` library, a toolkit for interacting with Large Language Models in Jupyter notebooks.\n",
    "\n",
    "**Date:** April 24, 2025\n",
    "\n",
    "## What is Cellmage?\n",
    "\n",
    "Cellmage is a library that simplifies interactions with various LLMs while providing:\n",
    "- Conversation history management\n",
    "- Persona configuration\n",
    "- Snippet management\n",
    "- Conversation saving/loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c7350",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "Let's start by ensuring we have the cellmage package installed. In this notebook, we'll use the existing installation from the local development environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19287fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:05,758 - cellmage - INFO - Cellmage logging initialized\n",
      "2025-04-24 06:21:05,767 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Project root directory: /Users/tpinto/madpin/cellmage\n",
      "Added path: /Users/tpinto/madpin/cellmage\n",
      "Cellmage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to sys.path so we can import cellmage\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ensure the cellmage package can be imported\n",
    "# Get the absolute path of the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the project root directory (parent of the notebook directory)\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added path: {project_root}\")\n",
    "\n",
    "try:\n",
    "    # Import cellmage\n",
    "    import cellmage\n",
    "\n",
    "    # Check version - handle case where __version__ might not be available\n",
    "    try:\n",
    "        print(f\"Cellmage version: {cellmage.__version__}\")\n",
    "    except AttributeError:\n",
    "        print(\"Cellmage imported successfully, but version information is not available\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error importing cellmage: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    print(\"\\nTry running this notebook from the project root directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7df73",
   "metadata": {},
   "source": [
    "## Setting Up the LLM Client\n",
    "\n",
    "Cellmage uses an adapter pattern to work with multiple LLM providers. The new `DirectLLMAdapter` provides direct HTTP communication with LLM APIs without requiring additional packages.\n",
    "\n",
    "Let's set up our LLM client to use OpenAI's GPT models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01f5e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:05,842 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_key' = sk-L...xxmA\n",
      "2025-04-24 06:21:05,843 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 06:21:05,843 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM client initialized with model: gpt-4.1-nano\n"
     ]
    }
   ],
   "source": [
    "from cellmage.adapters.direct_client import DirectLLMAdapter\n",
    "\n",
    "# Create an LLM client with GPT-4.1-nano model\n",
    "llm_client = DirectLLMAdapter(default_model=\"gpt-4.1-nano\")\n",
    "\n",
    "# You'll need to ensure your API key is set up in your environment\n",
    "# For OpenAI: export CELLMAGE_API_KEY=your_api_key\n",
    "# For testing we'll simulate a successful initialization\n",
    "print(\"LLM client initialized with model: gpt-4.1-nano\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5640c8ce",
   "metadata": {},
   "source": [
    "## Creating a Chat Manager\n",
    "\n",
    "The `ChatManager` is the central class in Cellmage that coordinates between all components. Let's create a basic setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70ea0b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:05,887 - cellmage.resources.memory_loader - INFO - Added persona 'helpful_assistant' to memory\n",
      "2025-04-24 06:21:05,888 - cellmage.chat_manager - INFO - Initializing ChatManager\n",
      "2025-04-24 06:21:05,888 - cellmage.config - INFO - python-dotenv not installed, skipping .env file loading\n",
      "2025-04-24 06:21:05,889 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 06:21:05,889 - cellmage.adapters.direct_client - INFO - [Override] Setting 'temperature' = 0.7\n",
      "2025-04-24 06:21:05,889 - cellmage.chat_manager - INFO - Default persona set to 'helpful_assistant'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat manager initialized with 'helpful_assistant' persona\n"
     ]
    }
   ],
   "source": [
    "# Create components for the chat manager\n",
    "from cellmage.resources.memory_loader import MemoryLoader\n",
    "from cellmage.storage.memory_store import MemoryStore\n",
    "\n",
    "# Create in-memory components for testing\n",
    "persona_loader = MemoryLoader()\n",
    "snippet_provider = MemoryLoader()\n",
    "history_store = MemoryStore()\n",
    "\n",
    "# Create a basic persona\n",
    "persona_loader.add_persona(\n",
    "    name=\"helpful_assistant\",\n",
    "    system_message=\"You are a helpful assistant who provides clear, concise answers.\",\n",
    "    config={\"temperature\": 0.7},\n",
    ")\n",
    "\n",
    "# Create a chat manager\n",
    "chat_manager = cellmage.ChatManager(\n",
    "    llm_client=llm_client,\n",
    "    persona_loader=persona_loader,\n",
    "    snippet_provider=snippet_provider,\n",
    "    history_store=history_store,\n",
    ")\n",
    "\n",
    "# Set default persona\n",
    "chat_manager.set_default_persona(\"helpful_assistant\")\n",
    "\n",
    "print(\"Chat manager initialized with 'helpful_assistant' persona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9bf4cd",
   "metadata": {},
   "source": [
    "## Sending Messages\n",
    "\n",
    "Now that our chat manager is set up, we can send messages to the LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb73e77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:05,894 - cellmage.chat_manager - INFO - Sending message to LLM with 2 messages in context\n",
      "2025-04-24 06:21:05,895 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 2 messages\n"
     ]
    }
   ],
   "source": [
    "# Send a message to the LLM\n",
    "response = chat_manager.chat(\n",
    "    \"What are the main features of the cellmage library?\",\n",
    "    stream=True,  # Enable streaming responses\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee4b0e",
   "metadata": {},
   "source": [
    "## Adding a Code Snippet\n",
    "\n",
    "Cellmage allows you to add code snippets to the conversation, which can be useful for providing context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2b3325",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:07,177 - cellmage.resources.memory_loader - INFO - Added snippet 'python_example' to memory\n",
      "2025-04-24 06:21:07,204 - cellmage.chat_manager - INFO - Added snippet 'python_example' as system message\n",
      "2025-04-24 06:21:07,218 - cellmage.chat_manager - INFO - Sending message to LLM with 5 messages in context\n",
      "2025-04-24 06:21:07,229 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 5 messages\n"
     ]
    }
   ],
   "source": [
    "# Create a code snippet\n",
    "snippet_provider.add_snippet(\n",
    "    name=\"python_example\",\n",
    "    content=\"\"\"```python\n",
    "def calculate_fibonacci(n):\n",
    "    if n <= 0:\n",
    "        return 0\n",
    "    elif n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)\n",
    "```\"\"\",\n",
    ")\n",
    "\n",
    "# Add the snippet to the conversation\n",
    "chat_manager.add_snippet(\"python_example\")\n",
    "\n",
    "# Now ask about the snippet\n",
    "response = chat_manager.chat(\n",
    "    \"Can you explain this fibonacci function and suggest how to make it more efficient?\", stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbda3da1",
   "metadata": {},
   "source": [
    "## Viewing Conversation History\n",
    "\n",
    "You can view the conversation history at any time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91126715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. system: You are a helpful assistant who provides clear, co...\n",
      "   ID: 4971705f-c997-4081-a75a-b92f038415d1\n",
      "\n",
      "2. user: What are the main features of the cellmage library...\n",
      "   ID: a15b0e1b-4bd7-41f5-b595-ccd2c8dd9aa9\n",
      "\n",
      "3. assistant: ...\n",
      "   ID: 7fd5ebf1-77ba-4916-b220-16cc7315435f\n",
      "\n",
      "4. system: ```python\n",
      "def calculate_fibonacci(n):\n",
      "    if n <= ...\n",
      "   ID: c2bd3e5d-839a-4c79-8e65-948705f9ffca\n",
      "\n",
      "5. user: Can you explain this fibonacci function and sugges...\n",
      "   ID: 5c6333ad-39f9-4ed0-ae83-dace731a6073\n",
      "\n",
      "6. assistant: ...\n",
      "   ID: aeffcc08-a9b8-4724-aba0-8e1acfc73941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the conversation history\n",
    "history = chat_manager.get_history()\n",
    "\n",
    "# Print the history in a readable format\n",
    "for i, message in enumerate(history):\n",
    "    print(f\"{i + 1}. {message.role}: {message.content[:50]}...\")\n",
    "    print(f\"   ID: {message.id}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cebd3ba",
   "metadata": {},
   "source": [
    "## Saving and Loading Conversations\n",
    "\n",
    "Cellmage allows you to save and load conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "300410f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 06:21:13,815 - cellmage.storage.memory_store - INFO - Saved conversation to memory with ID: example_conversation\n",
      "2025-04-24 06:21:13,821 - cellmage.history_manager - INFO - History cleared. Kept 2 system messages.\n",
      "2025-04-24 06:21:13,825 - cellmage.history_manager - INFO - Loaded conversation from example_conversation with 6 messages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation saved to: example_conversation\n",
      "History cleared, current message count: 2\n",
      "Conversation loaded, message count: 6\n"
     ]
    }
   ],
   "source": [
    "# Save the conversation\n",
    "save_path = chat_manager.save_conversation(\"example_conversation\")\n",
    "print(f\"Conversation saved to: {save_path}\")\n",
    "\n",
    "# Clear the history\n",
    "chat_manager.clear_history()\n",
    "print(f\"History cleared, current message count: {len(chat_manager.get_history())}\")\n",
    "\n",
    "# Load the conversation back\n",
    "if save_path:\n",
    "    chat_manager.load_conversation(save_path)\n",
    "    print(f\"Conversation loaded, message count: {len(chat_manager.get_history())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606d7dd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the basic functionality of the Cellmage library:\n",
    "- Setting up an LLM client\n",
    "- Creating and using personas\n",
    "- Adding code snippets\n",
    "- Sending messages to the LLM\n",
    "- Viewing conversation history\n",
    "- Saving and loading conversations\n",
    "\n",
    "In the next notebooks, we'll explore more advanced features and test with different LLM models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
