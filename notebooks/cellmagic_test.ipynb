{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5c35fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:07:06,555 - cellmage - INFO - Cellmage logging initialized\n",
      "2025-04-24 18:07:06,566 - cellmage.config - INFO - Loaded environment variables from .env file\n",
      "2025-04-24 18:07:06,566 - cellmage.config - INFO - Loaded environment variables from .env file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook directory: /Users/tpinto/madpin/cellmage/notebooks\n",
      "Project root directory: /Users/tpinto/madpin/cellmage\n",
      "Added path: /Users/tpinto/madpin/cellmage\n",
      "Cellmage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Add the parent directory to sys.path so we can import cellmage\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Ensure the cellmage package can be imported\n",
    "# Get the absolute path of the current working directory\n",
    "notebook_dir = os.getcwd()\n",
    "# Get the project root directory (parent of the notebook directory)\n",
    "project_root = os.path.abspath(os.path.join(notebook_dir, \"..\"))\n",
    "\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "print(f\"Project root directory: {project_root}\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    print(f\"Added path: {project_root}\")\n",
    "\n",
    "try:\n",
    "    # Import cellmage\n",
    "    import cellmage\n",
    "\n",
    "    # Check version - handle case where __version__ might not be available\n",
    "    try:\n",
    "        print(f\"Cellmage version: {cellmage.__version__}\")\n",
    "    except AttributeError:\n",
    "        print(\"Cellmage imported successfully, but version information is not available\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Error importing cellmage: {e}\")\n",
    "    print(\"\\nDebug information:\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    print(f\"Python path: {sys.path}\")\n",
    "    print(\"\\nTry running this notebook from the project root directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:07:06,874 - cellmage.integrations.ipython_magic - INFO - Initializing default ChatManager components...\n",
      "2025-04-24 18:07:06,874 - cellmage.resources.file_loader - INFO - Directory setup: /Users/tpinto/madpin/cellmage/notebooks/llm_personas\n",
      "2025-04-24 18:07:06,875 - cellmage.resources.file_loader - INFO - Directory setup: /Users/tpinto/madpin/cellmage/notebooks/snippets\n",
      "2025-04-24 18:07:06,876 - cellmage.storage.markdown_store - INFO - Save directory setup: /Users/tpinto/madpin/cellmage/notebooks/llm_conversations\n",
      "2025-04-24 18:07:06,876 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_key' = sk-L...xxmA\n",
      "2025-04-24 18:07:06,876 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 18:07:06,877 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 18:07:06,877 - cellmage.chat_manager - INFO - Initializing ChatManager\n",
      "2025-04-24 18:07:06,878 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 18:07:06,878 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 18:07:06,878 - cellmage.integrations.ipython_magic - INFO - Default ChatManager initialized successfully.\n",
      "2025-04-24 18:07:06,878 - cellmage.integrations.ipython_magic - INFO - NotebookLLMMagics initialized and ChatManager accessed successfully.\n",
      "2025-04-24 18:07:06,874 - cellmage.resources.file_loader - INFO - Directory setup: /Users/tpinto/madpin/cellmage/notebooks/llm_personas\n",
      "2025-04-24 18:07:06,875 - cellmage.resources.file_loader - INFO - Directory setup: /Users/tpinto/madpin/cellmage/notebooks/snippets\n",
      "2025-04-24 18:07:06,876 - cellmage.storage.markdown_store - INFO - Save directory setup: /Users/tpinto/madpin/cellmage/notebooks/llm_conversations\n",
      "2025-04-24 18:07:06,876 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_key' = sk-L...xxmA\n",
      "2025-04-24 18:07:06,876 - cellmage.adapters.direct_client - INFO - [Override] Setting 'api_base' = https://litellm.oracle.madpin.dev\n",
      "2025-04-24 18:07:06,877 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 18:07:06,877 - cellmage.chat_manager - INFO - Initializing ChatManager\n",
      "2025-04-24 18:07:06,878 - cellmage.adapters.direct_client - INFO - [Override] Setting 'model' = gpt-4.1-nano\n",
      "2025-04-24 18:07:06,878 - cellmage.chat_manager - INFO - ChatManager initialized\n",
      "2025-04-24 18:07:06,878 - cellmage.integrations.ipython_magic - INFO - Default ChatManager initialized successfully.\n",
      "2025-04-24 18:07:06,878 - cellmage.integrations.ipython_magic - INFO - NotebookLLMMagics initialized and ChatManager accessed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NotebookLLM Magics loaded. Use %llm_config and %%llm.\n",
      "‚úÖ CellMage extension loaded successfully\n",
      "Available line magics:\n",
      "alias, alias_magic, autoawait, autocall, automagic, autosave, bookmark, cat, cd, clear, code_wrap, colors, conda, config, connect_info, cp, debug, dhist, dirs, doctest_mode, ed, edit, env, gui, hist, history, killbgscripts, ldir, less, lf, lk, ll, llm_config, load, load_ext, loadpy, logoff, logon, logstart, logstate, logstop, ls, lsmagic, lx, macro, magic, mamba, man, matplotlib, micromamba, mkdir, more, mv, notebook, page, pastebin, pdb, pdef, pdoc, pfile, pinfo, pinfo2, pip, popd, pprint, precision, prun, psearch, psource, pushd, pwd, pycat, pylab, qtconsole, quickref, recall, rehashx, reload_ext, rep, rerun, reset, reset_selective, rm, rmdir, run, save, sc, set_env, store, sx, system, tb, time, timeit, unalias, unload_ext, uv, who, who_ls, whos, xdel, xmode\n",
      "\n",
      "Available cell magics:\n",
      "!, HTML, SVG, bash, capture, code_wrap, debug, file, html, javascript, js, latex, llm, markdown, perl, prun, pypy, python, python2, python3, ruby, script, sh, svg, sx, system, time, timeit, writefile\n",
      "\n",
      "CellMage version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the CellMage extension\n",
    "try:\n",
    "    %load_ext cellmage\n",
    "    print(\"‚úÖ CellMage extension loaded successfully\")\n",
    "\n",
    "    # Check if IPython is available and get available magics\n",
    "    import IPython\n",
    "\n",
    "    ipython = IPython.get_ipython()\n",
    "    if ipython:\n",
    "        print(\"Available line magics:\")\n",
    "        print(\", \".join(sorted(ipython.magics_manager.lsmagic()[\"line\"])))\n",
    "\n",
    "        # Display CellMage magics specifically\n",
    "        print(\"\\nAvailable cell magics:\")\n",
    "        print(\", \".join(sorted(ipython.magics_manager.lsmagic()[\"cell\"])))\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading CellMage extension: {e}\")\n",
    "\n",
    "# Display version information\n",
    "import cellmage\n",
    "\n",
    "print(f\"\\nCellMage version: {cellmage.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150bc60f",
   "metadata": {},
   "source": [
    "## 2. Configuring CellMage with `%llm_config`\n",
    "\n",
    "The `%llm_config` (or equivalently, `%llm_setup`) magic command allows you to configure CellMage's behavior, including setting the default model, selecting personas, and managing conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14aa928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- NotebookLLM Status ---\n",
      "Session ID: 5c7b0967-93ba-49dd-afee-3d2bd3f6408c\n",
      "None\n",
      "Active Overrides: {'api_key': 'sk-L...mA', 'api_base': 'https://litellm.oracle.madpin.dev', 'model': 'gpt-4.1-nano'}\n",
      "History Length: 0 messages\n",
      "--------------------------\n",
      "Available Personas: None\n"
     ]
    }
   ],
   "source": [
    "# Basic configuration\n",
    "%llm_config --status\n",
    "\n",
    "# You can set the default LLM model\n",
    "%llm_config --model gpt-4.1-nano\n",
    "\n",
    "# List available personas\n",
    "%llm_config --list-personas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71492569",
   "metadata": {},
   "source": [
    "### Setting API Credentials\n",
    "\n",
    "To connect to LLM services, you need to provide API credentials. While we recommend using environment variables, you can also set these directly in your notebook:\n",
    "\n",
    "```python\n",
    "%llm_config --api_key \"your-api-key\" --api_base \"https://api.example.com/v1\"\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Security Warning**: Never commit notebooks with API keys to version control!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02578cda",
   "metadata": {},
   "source": [
    "## 3. Using the `%%llm` Cell Magic\n",
    "\n",
    "The core functionality of CellMage is the `%%llm` cell magic. Simply add this to the top of any cell, and the cell's content will be sent as a prompt to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f040f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "A Jupyter notebook is an interactive, web-based tool that allows data scientists and researchers to combine writing code, visualizations, and explanatory text all in one place. It's like a digital notebook where you can write, run, and see the results of your code immediately, making it easier to explore data, perform analysis, and share your work. The main advantage is that it combines code execution with rich formatting options like charts, images, and markdown text, which helps in documenting your thought process and findings clearly.\n",
       "\n",
       "In a Jupyter notebook, you work in cells‚Äîsome containing code (usually in Python, but other languages are also supported), and others containing text written in Markdown for explanations or titles. When you run a code cell, the output appears directly below it, which makes it simple to test ideas and see results instantly. This interactive setup is especially useful in data science because it encourages experimentation, iterative analysis, and easy visualization of data patterns, making complex insights more accessible and easier to communicate."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:07:06,895 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 1 messages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ‚úì gpt-4.1-nano ‚Ä¢ 10.07s ‚Ä¢ 22‚Üì/274‚Üë tokens ‚Ä¢ $4.22¬¢\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm \n",
    "Explain the concept of a Jupyter notebook to someone new to data science in 2-3 paragraphs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3de8731",
   "metadata": {},
   "source": [
    "### Using Options with `%%llm`\n",
    "\n",
    "You can customize the behavior of individual LLM interactions by passing options to the `%%llm` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d83f019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Assistant:**\n",
       "Printing out some lines,  \n",
       "Syntax guides the silent flow,  \n",
       "Code comes alive now."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 18:07:16,970 - cellmage.adapters.direct_client - INFO - Calling model 'gpt-4.1-nano' with 3 messages\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background-color: #f1f8e9; border: 1px solid #c5e1a5; color: #33691e;\n",
       "                    padding: 3px 6px; margin-top: 4px; border-radius: 3px; font-family: monospace; \n",
       "                    font-size: 0.75em; line-height: 1.2; display: inline-block; opacity: 0.85;\">\n",
       "            ‚úì gpt-4.1 ‚Ä¢ 0.68s ‚Ä¢ 308‚Üì/20‚Üë tokens ‚Ä¢ $1.84¬¢\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%llm --model gpt-4.1 --temperature 1.5\n",
    "Write a haiku about programmin2g in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b16a308",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This is a test error to demonstrate automatic rollback in CellMage.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test error to demonstrate automatic rollback in CellMage.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: This is a test error to demonstrate automatic rollback in CellMage."
     ]
    }
   ],
   "source": [
    "raise ValueError(\"This is a test error to demonstrate automatic rollback in CellMage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a5a05c",
   "metadata": {},
   "source": [
    "## 4. Working with Personas\n",
    "\n",
    "Personas are predefined configurations that include system prompts and LLM parameters. They help you quickly switch between different interaction styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e95b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm --persona python_expert\n",
    "Explain how decorators work in Python with a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a default persona for all subsequent interactions\n",
    "%llm_config --persona creative_writer\n",
    "%llm_config --show-persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Write a short poem about artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93190aee",
   "metadata": {},
   "source": [
    "## 5. Managing Conversation History\n",
    "\n",
    "CellMage automatically maintains conversation history to provide context for your interactions. You can manage this history using various commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1117bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the current conversation history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the conversation history\n",
    "%llm_config --clear-history\n",
    "\n",
    "# Verify that the history is cleared\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca7367",
   "metadata": {},
   "source": [
    "### Automatic Rollback\n",
    "\n",
    "One of CellMage's most useful features is automatic rollback. When you re-run a cell that contains `%%llm`, CellMage automatically removes the previous interaction from that cell from the history. This prevents duplication when you're iterating on your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Explain what 'automatic rollback' means in the context of CellMage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError(\"This is a test error to trigger automatic rollback in CellMage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebe1df1",
   "metadata": {},
   "source": [
    "## 6. Using Snippets\n",
    "\n",
    "Snippets allow you to include code or other content as context in your LLM conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b25ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a sample code snippet first\n",
    "%%writefile /tmp/example_code.py\n",
    "\n",
    "\n",
    "def process_data(data_list):\n",
    "    \"\"\"Process a list of numeric data.\"\"\"\n",
    "    results = []\n",
    "    for item in data_list:\n",
    "        if isinstance(item, (int, float)):\n",
    "            results.append(item * 2)\n",
    "        else:\n",
    "            print(f\"Skipping non-numeric item: {item}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "sample_data = [1, 2, \"3\", 4.5, \"text\"]\n",
    "processed = process_data(sample_data)\n",
    "print(f\"Processed data: {processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780b652",
   "metadata": {},
   "source": [
    "Now we can list available snippets and add one to our conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70647b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available snippets\n",
    "%llm_config --list-snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our file as a snippet\n",
    "%llm_config --snippets /tmp/example_code.py system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a11de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm --persona python_expert\n",
    "Review the code I provided. How could I improve the error handling and make the function more robust?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c12c7",
   "metadata": {},
   "source": [
    "## 7. Saving and Loading Conversations\n",
    "\n",
    "CellMage allows you to save your conversation history and load it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current conversation\n",
    "%llm_config --save code_review_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532da41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear history\n",
    "%llm_config --clear-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available saved sessions\n",
    "%llm_config --list-sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290836ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a previously saved session\n",
    "%llm_config --load code_review_session\n",
    "\n",
    "# Show the loaded history\n",
    "%llm_config --show-history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40607d",
   "metadata": {},
   "source": [
    "## 8. Using Parameter Overrides\n",
    "\n",
    "You can temporarily override LLM parameters for specific interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a parameter override\n",
    "%llm_config --set-override temperature 0.9\n",
    "\n",
    "# Show current overrides\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22af50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%llm\n",
    "Generate three creative startup ideas combining artificial intelligence and sustainable energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205edb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all overrides\n",
    "%llm_config --clear-overrides\n",
    "\n",
    "# Verify overrides are cleared\n",
    "%llm_config --show-overrides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d8eb0",
   "metadata": {},
   "source": [
    "## 9. Ambient Mode with `%llm_setup_forever`\n",
    "\n",
    "For a pure chat experience, you can enable \"Ambient Enchantment\" mode, which treats all regular code cells as prompts for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0801b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable ambient mode\n",
    "%llm_setup_forever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b7a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regular cell will be treated as a prompt for the LLM\n",
    "What are three best practices for writing clean, maintainable Python code?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd14313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable ambient mode when you're done\n",
    "%disable_llm_setup_forever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4e9ceb",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting and Tips\n",
    "\n",
    "Here are some common issues and how to resolve them:\n",
    "\n",
    "1. **Magic commands not found**: Make sure you've loaded the extension with `%load_ext cellmage`\n",
    "2. **API connection errors**: Check your API key and connection settings\n",
    "3. **Missing personas or snippets**: Use `--list-personas` or `--list-snippets` to check available resources\n",
    "4. **Memory errors**: Try clearing history with `--clear-history` to free up memory\n",
    "5. **Import errors**: Verify the CellMage package is correctly installed in your Python path\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "- Use `--no-stream` for non-interactive tasks to get the full response at once\n",
    "- Keep conversation history concise for faster responses\n",
    "- Choose appropriate models for your task (smaller models for simple tasks, larger models for complex reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493ace29",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "CellMage's magic functions provide a seamless way to integrate LLM capabilities directly into your Jupyter workflow. By using these magic commands, you can:\n",
    "\n",
    "- Interact with LLMs without leaving your notebook\n",
    "- Maintain conversation context across cells\n",
    "- Customize LLM behavior with personas and parameter settings\n",
    "- Save and load conversations for later use\n",
    "- Provide additional context through snippets\n",
    "\n",
    "This makes CellMage a powerful tool for data scientists, researchers, and developers who want to leverage LLMs in their workflow.\n",
    "\n",
    "Happy conjuring! ‚ú®üßô‚Äç‚ôÇÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
